{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# coding=utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "import random\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout,LSTM,BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Major_Axis</th>\n",
       "      <th>Minor_Axis</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Eqdiasq</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Aspect_Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>StdDev_RR</th>\n",
       "      <th>StdDev_RG</th>\n",
       "      <th>StdDev_RB</th>\n",
       "      <th>Skew_RR</th>\n",
       "      <th>Skew_RG</th>\n",
       "      <th>Skew_RB</th>\n",
       "      <th>Kurtosis_RR</th>\n",
       "      <th>Kurtosis_RG</th>\n",
       "      <th>Kurtosis_RB</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>84923</td>\n",
       "      <td>1199.2190</td>\n",
       "      <td>469.3299</td>\n",
       "      <td>232.0247</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>328.8272</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>86519</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>2.0228</td>\n",
       "      <td>...</td>\n",
       "      <td>21.2477</td>\n",
       "      <td>22.4891</td>\n",
       "      <td>22.9599</td>\n",
       "      <td>-1.1784</td>\n",
       "      <td>-0.9764</td>\n",
       "      <td>-0.7704</td>\n",
       "      <td>3.8433</td>\n",
       "      <td>3.2281</td>\n",
       "      <td>2.6371</td>\n",
       "      <td>Siirt_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>85845</td>\n",
       "      <td>2041.5470</td>\n",
       "      <td>490.6570</td>\n",
       "      <td>237.4381</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>330.6074</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>96011</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>2.0665</td>\n",
       "      <td>...</td>\n",
       "      <td>21.4586</td>\n",
       "      <td>22.7930</td>\n",
       "      <td>27.0073</td>\n",
       "      <td>-0.7880</td>\n",
       "      <td>-0.5331</td>\n",
       "      <td>-0.5011</td>\n",
       "      <td>3.0151</td>\n",
       "      <td>2.8876</td>\n",
       "      <td>4.2760</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>84880</td>\n",
       "      <td>1458.6570</td>\n",
       "      <td>475.3602</td>\n",
       "      <td>246.4661</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>328.7439</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>91934</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>1.9287</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5703</td>\n",
       "      <td>23.0201</td>\n",
       "      <td>21.6779</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>-0.7448</td>\n",
       "      <td>-0.2291</td>\n",
       "      <td>3.6905</td>\n",
       "      <td>3.4721</td>\n",
       "      <td>3.5018</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>54601</td>\n",
       "      <td>1348.1689</td>\n",
       "      <td>421.2827</td>\n",
       "      <td>182.4424</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>263.6667</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>62274</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>2.3091</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4110</td>\n",
       "      <td>16.1671</td>\n",
       "      <td>18.2462</td>\n",
       "      <td>-0.2044</td>\n",
       "      <td>-0.0904</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>2.7345</td>\n",
       "      <td>3.1792</td>\n",
       "      <td>3.2125</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>68626</td>\n",
       "      <td>1407.5320</td>\n",
       "      <td>448.5386</td>\n",
       "      <td>198.9794</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>295.5966</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>72456</td>\n",
       "      <td>0.7662</td>\n",
       "      <td>2.2542</td>\n",
       "      <td>...</td>\n",
       "      <td>24.4091</td>\n",
       "      <td>25.6984</td>\n",
       "      <td>28.5108</td>\n",
       "      <td>-0.8011</td>\n",
       "      <td>-0.6479</td>\n",
       "      <td>-0.6135</td>\n",
       "      <td>2.5193</td>\n",
       "      <td>2.4528</td>\n",
       "      <td>2.4083</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>67659</td>\n",
       "      <td>1446.4280</td>\n",
       "      <td>396.5165</td>\n",
       "      <td>226.1531</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>293.5066</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>74071</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>1.7533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0826</td>\n",
       "      <td>24.0397</td>\n",
       "      <td>24.7538</td>\n",
       "      <td>-0.4170</td>\n",
       "      <td>-0.4411</td>\n",
       "      <td>-0.3590</td>\n",
       "      <td>2.2057</td>\n",
       "      <td>2.3340</td>\n",
       "      <td>2.6809</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>41269</td>\n",
       "      <td>1338.3800</td>\n",
       "      <td>370.0265</td>\n",
       "      <td>153.0344</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>229.2277</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>46369</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>2.4179</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0830</td>\n",
       "      <td>19.2815</td>\n",
       "      <td>19.6241</td>\n",
       "      <td>-0.3768</td>\n",
       "      <td>-0.2495</td>\n",
       "      <td>-0.0783</td>\n",
       "      <td>2.1682</td>\n",
       "      <td>2.0709</td>\n",
       "      <td>2.2075</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>81164</td>\n",
       "      <td>1222.9310</td>\n",
       "      <td>442.9454</td>\n",
       "      <td>242.1429</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>321.4673</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>86419</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>1.8293</td>\n",
       "      <td>...</td>\n",
       "      <td>21.4675</td>\n",
       "      <td>23.0536</td>\n",
       "      <td>23.5558</td>\n",
       "      <td>-0.9706</td>\n",
       "      <td>-0.7575</td>\n",
       "      <td>-0.5712</td>\n",
       "      <td>3.3370</td>\n",
       "      <td>3.0248</td>\n",
       "      <td>3.1850</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>67270</td>\n",
       "      <td>1084.4500</td>\n",
       "      <td>425.1971</td>\n",
       "      <td>204.9928</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>292.6616</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>69272</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>2.0742</td>\n",
       "      <td>...</td>\n",
       "      <td>24.1879</td>\n",
       "      <td>26.4544</td>\n",
       "      <td>27.2019</td>\n",
       "      <td>-0.8846</td>\n",
       "      <td>-0.6758</td>\n",
       "      <td>-0.4558</td>\n",
       "      <td>2.9020</td>\n",
       "      <td>2.5082</td>\n",
       "      <td>2.3304</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>61365</td>\n",
       "      <td>1042.7690</td>\n",
       "      <td>416.7724</td>\n",
       "      <td>190.9898</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>279.5216</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>62716</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>2.1822</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3367</td>\n",
       "      <td>15.5665</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>-0.3976</td>\n",
       "      <td>-0.1698</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>3.8909</td>\n",
       "      <td>4.1458</td>\n",
       "      <td>5.1740</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  Perimeter  Major_Axis  Minor_Axis  Eccentricity   Eqdiasq  \\\n",
       "1423  84923  1199.2190    469.3299    232.0247        0.8692  328.8272   \n",
       "871   85845  2041.5470    490.6570    237.4381        0.8751  330.6074   \n",
       "96    84880  1458.6570    475.3602    246.4661        0.8551  328.7439   \n",
       "942   54601  1348.1689    421.2827    182.4424        0.9014  263.6667   \n",
       "239   68626  1407.5320    448.5386    198.9794        0.8962  295.5966   \n",
       "718   67659  1446.4280    396.5165    226.1531        0.8214  293.5066   \n",
       "881   41269  1338.3800    370.0265    153.0344        0.9105  229.2277   \n",
       "70    81164  1222.9310    442.9454    242.1429        0.8374  321.4673   \n",
       "1065  67270  1084.4500    425.1971    204.9928        0.8761  292.6616   \n",
       "409   61365  1042.7690    416.7724    190.9898        0.8888  279.5216   \n",
       "\n",
       "      Solidity  Convex_Area  Extent  Aspect_Ratio  ...  StdDev_RR  StdDev_RG  \\\n",
       "1423    0.9816        86519  0.6558        2.0228  ...    21.2477    22.4891   \n",
       "871     0.8941        96011  0.7345        2.0665  ...    21.4586    22.7930   \n",
       "96      0.9233        91934  0.7060        1.9287  ...    20.5703    23.0201   \n",
       "942     0.8768        62274  0.5580        2.3091  ...    15.4110    16.1671   \n",
       "239     0.9471        72456  0.7662        2.2542  ...    24.4091    25.6984   \n",
       "718     0.9134        74071  0.7631        1.7533  ...    23.0826    24.0397   \n",
       "881     0.8900        46369  0.6439        2.4179  ...    18.0830    19.2815   \n",
       "70      0.9392        86419  0.7543        1.8293  ...    21.4675    23.0536   \n",
       "1065    0.9711        69272  0.7504        2.0742  ...    24.1879    26.4544   \n",
       "409     0.9785        62716  0.7165        2.1822  ...    15.3367    15.5665   \n",
       "\n",
       "      StdDev_RB  Skew_RR  Skew_RG  Skew_RB  Kurtosis_RR  Kurtosis_RG  \\\n",
       "1423    22.9599  -1.1784  -0.9764  -0.7704       3.8433       3.2281   \n",
       "871     27.0073  -0.7880  -0.5331  -0.5011       3.0151       2.8876   \n",
       "96      21.6779  -0.7622  -0.7448  -0.2291       3.6905       3.4721   \n",
       "942     18.2462  -0.2044  -0.0904   0.1528       2.7345       3.1792   \n",
       "239     28.5108  -0.8011  -0.6479  -0.6135       2.5193       2.4528   \n",
       "718     24.7538  -0.4170  -0.4411  -0.3590       2.2057       2.3340   \n",
       "881     19.6241  -0.3768  -0.2495  -0.0783       2.1682       2.0709   \n",
       "70      23.5558  -0.9706  -0.7575  -0.5712       3.3370       3.0248   \n",
       "1065    27.2019  -0.8846  -0.6758  -0.4558       2.9020       2.5082   \n",
       "409     16.7052  -0.3976  -0.1698   0.4866       3.8909       4.1458   \n",
       "\n",
       "      Kurtosis_RB              Class  \n",
       "1423       2.6371    Siirt_Pistachio  \n",
       "871        4.2760  Kirmizi_Pistachio  \n",
       "96         3.5018  Kirmizi_Pistachio  \n",
       "942        3.2125  Kirmizi_Pistachio  \n",
       "239        2.4083  Kirmizi_Pistachio  \n",
       "718        2.6809  Kirmizi_Pistachio  \n",
       "881        2.2075  Kirmizi_Pistachio  \n",
       "70         3.1850  Kirmizi_Pistachio  \n",
       "1065       2.3304  Kirmizi_Pistachio  \n",
       "409        5.1740  Kirmizi_Pistachio  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./Pistachio_Dataset/Pistachio_28_Features_Dataset/Pistachio_28_Features_Dataset.csv') \n",
    "cols = ['Area', 'Perimeter', 'Major_Axis', 'Minor_Axis', 'Eccentricity',\n",
    "        'Eqdiasq', 'Solidity', 'Convex_Area', 'Extent', 'Aspect_Ratio',\n",
    "        'Roundness', 'Compactness', 'Shapefactor_1', 'Shapefactor_2',\n",
    "        'Shapefactor_3', 'Shapefactor_4', 'Mean_RR', 'Mean_RG', 'Mean_RB',\n",
    "        'StdDev_RR', 'StdDev_RG', 'StdDev_RB', 'Skew_RR', 'Skew_RG', 'Skew_RB',\n",
    "        'Kurtosis_RR', 'Kurtosis_RG', 'Kurtosis_RB','Class']\n",
    "# dataset = dataset.loc[:,cols]\n",
    "# d = {'Class': dataset['Class'].value_counts().index, 'count': dataset['Class'].value_counts()}\n",
    "# df_Class = pd.DataFrame(data=d).reset_index(drop=True)\n",
    "# df_Class\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for i in range(28):\n",
    "    lis.append(27-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FReIndex(colIndex,reIndex):\n",
    "    dirindex = {}\n",
    "    lisindex = []\n",
    "    for i in range(len(colIndex)):\n",
    "        lisindex.append(i)\n",
    "    dirindex = dict(zip(lisindex,colIndex))\n",
    "    colIndex = []\n",
    "    for i in range(len(reIndex)):\n",
    "        for key in dirindex:\n",
    "            if int(key) == int(reIndex[i]):\n",
    "                colIndex.append(dirindex[key])\n",
    "                break\n",
    "    print(colIndex)\n",
    "    return colIndex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Minor_Axis</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Eqdiasq</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Aspect_Ratio</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Shapefactor_1</th>\n",
       "      <th>Shapefactor_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>83711</td>\n",
       "      <td>256.2626</td>\n",
       "      <td>0.8458</td>\n",
       "      <td>326.4723</td>\n",
       "      <td>98431</td>\n",
       "      <td>1.8745</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.4619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>61836</td>\n",
       "      <td>238.2245</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>280.5923</td>\n",
       "      <td>75468</td>\n",
       "      <td>1.5913</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>89823</td>\n",
       "      <td>264.6333</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>338.1807</td>\n",
       "      <td>96010</td>\n",
       "      <td>1.7011</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>98290</td>\n",
       "      <td>303.0911</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>353.7608</td>\n",
       "      <td>105919</td>\n",
       "      <td>1.4426</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.6546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>77788</td>\n",
       "      <td>245.5920</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>314.7106</td>\n",
       "      <td>80677</td>\n",
       "      <td>1.6811</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>91872</td>\n",
       "      <td>264.0024</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>342.0162</td>\n",
       "      <td>97708</td>\n",
       "      <td>1.7228</td>\n",
       "      <td>0.7520</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.5655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>75516</td>\n",
       "      <td>245.7620</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>310.0806</td>\n",
       "      <td>82546</td>\n",
       "      <td>1.6753</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.5672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>94328</td>\n",
       "      <td>257.9542</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>346.5576</td>\n",
       "      <td>95643</td>\n",
       "      <td>1.8179</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.5461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>92155</td>\n",
       "      <td>244.4703</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>342.5425</td>\n",
       "      <td>94256</td>\n",
       "      <td>1.9899</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>93976</td>\n",
       "      <td>255.7460</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>345.9103</td>\n",
       "      <td>94871</td>\n",
       "      <td>1.8419</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.5392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  Minor_Axis  Eccentricity   Eqdiasq  Convex_Area  Aspect_Ratio  \\\n",
       "987   83711    256.2626        0.8458  326.4723        98431        1.8745   \n",
       "330   61836    238.2245        0.7779  280.5923        75468        1.5913   \n",
       "1404  89823    264.6333        0.8090  338.1807        96010        1.7011   \n",
       "1407  98290    303.0911        0.7207  353.7608       105919        1.4426   \n",
       "1971  77788    245.5920        0.8038  314.7106        80677        1.6811   \n",
       "...     ...         ...           ...       ...          ...           ...   \n",
       "1607  91872    264.0024        0.8143  342.0162        97708        1.7228   \n",
       "1039  75516    245.7620        0.8023  310.0806        82546        1.6753   \n",
       "1434  94328    257.9542        0.8351  346.5576        95643        1.8179   \n",
       "1812  92155    244.4703        0.8646  342.5425        94256        1.9899   \n",
       "2068  93976    255.7460        0.8398  345.9103        94871        1.8419   \n",
       "\n",
       "      Compactness  Shapefactor_1  Shapefactor_3  \n",
       "987        0.6796         0.0057         0.4619  \n",
       "330        0.7402         0.0061         0.5479  \n",
       "1404       0.7512         0.0050         0.5643  \n",
       "1407       0.8091         0.0044         0.6546  \n",
       "1971       0.7622         0.0053         0.5810  \n",
       "...           ...            ...            ...  \n",
       "1607       0.7520         0.0050         0.5655  \n",
       "1039       0.7531         0.0055         0.5672  \n",
       "1434       0.7390         0.0050         0.5461  \n",
       "1812       0.7041         0.0053         0.4958  \n",
       "2068       0.7343         0.0050         0.5392  \n",
       "\n",
       "[2130 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lisclass = dataset['Class'].values\n",
    "LisClassNp = []\n",
    "for i in range(len(Lisclass)):\n",
    "    if (Lisclass[i] == 'Kirmizi_Pistachio'):\n",
    "        LisClassNp.append([0,1])\n",
    "    else:\n",
    "        LisClassNp.append([1,0])\n",
    "Y = np.array(LisClassNp)\n",
    "dataset = dataset.drop(columns='Class')\n",
    "# lisindex = []\n",
    "# for i in range(len(dataset.columns)):\n",
    "#     lisindex.append(i)\n",
    "# dataset = dataset.reindex(lisindex)\n",
    "colIndex = ['Area','Minor_Axis', 'Eccentricity',\n",
    "            'Eqdiasq','Convex_Area', 'Aspect_Ratio',\n",
    "            'Compactness', 'Shapefactor_1', \n",
    "            'Shapefactor_3']\n",
    "#colIndex = FReIndex(colIndex,lis)\n",
    "dataset = pd.DataFrame(dataset,columns=colIndex)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "#拆分训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=40)\n",
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,sys\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('models')  \n",
    "os.mkdir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 16)             1664      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 16)             2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 6,101\n",
      "Trainable params: 6,005\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 10s 27ms/step - loss: 0.5390 - categorical_accuracy: 0.6962 - val_loss: 0.6840 - val_categorical_accuracy: 0.5781\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4888 - categorical_accuracy: 0.8197 - val_loss: 0.6820 - val_categorical_accuracy: 0.5781\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4760 - categorical_accuracy: 0.8278 - val_loss: 0.6755 - val_categorical_accuracy: 0.5781\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4839 - categorical_accuracy: 0.8145 - val_loss: 0.6673 - val_categorical_accuracy: 0.6198\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4682 - categorical_accuracy: 0.8214 - val_loss: 0.6448 - val_categorical_accuracy: 0.7083\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4642 - categorical_accuracy: 0.8290 - val_loss: 0.6073 - val_categorical_accuracy: 0.8594\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4594 - categorical_accuracy: 0.8284 - val_loss: 0.5538 - val_categorical_accuracy: 0.8542\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4565 - categorical_accuracy: 0.8209 - val_loss: 0.5028 - val_categorical_accuracy: 0.8490\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4524 - categorical_accuracy: 0.8261 - val_loss: 0.4703 - val_categorical_accuracy: 0.8594\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4458 - categorical_accuracy: 0.8261 - val_loss: 0.4492 - val_categorical_accuracy: 0.8646\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4478 - categorical_accuracy: 0.8278 - val_loss: 0.4480 - val_categorical_accuracy: 0.8854\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4412 - categorical_accuracy: 0.8272 - val_loss: 0.4255 - val_categorical_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4474 - categorical_accuracy: 0.8157 - val_loss: 0.4054 - val_categorical_accuracy: 0.8698\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4358 - categorical_accuracy: 0.8301 - val_loss: 0.4385 - val_categorical_accuracy: 0.8438\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4262 - categorical_accuracy: 0.8446 - val_loss: 0.4072 - val_categorical_accuracy: 0.8854\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4262 - categorical_accuracy: 0.8313 - val_loss: 0.4001 - val_categorical_accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4233 - categorical_accuracy: 0.8365 - val_loss: 0.4634 - val_categorical_accuracy: 0.8125\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4209 - categorical_accuracy: 0.8330 - val_loss: 0.4249 - val_categorical_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4160 - categorical_accuracy: 0.8296 - val_loss: 0.3939 - val_categorical_accuracy: 0.8802\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4100 - categorical_accuracy: 0.8330 - val_loss: 0.3856 - val_categorical_accuracy: 0.8698\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4078 - categorical_accuracy: 0.8365 - val_loss: 0.4079 - val_categorical_accuracy: 0.8438\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4121 - categorical_accuracy: 0.8296 - val_loss: 0.4049 - val_categorical_accuracy: 0.8490\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4213 - categorical_accuracy: 0.8319 - val_loss: 0.3901 - val_categorical_accuracy: 0.8490\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3999 - categorical_accuracy: 0.8435 - val_loss: 0.4242 - val_categorical_accuracy: 0.8229\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4118 - categorical_accuracy: 0.8301 - val_loss: 0.3924 - val_categorical_accuracy: 0.8594\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4128 - categorical_accuracy: 0.8278 - val_loss: 0.3907 - val_categorical_accuracy: 0.8594\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4004 - categorical_accuracy: 0.83 - 0s 5ms/step - loss: 0.4001 - categorical_accuracy: 0.8383 - val_loss: 0.3833 - val_categorical_accuracy: 0.8698\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4127 - categorical_accuracy: 0.8359 - val_loss: 0.3772 - val_categorical_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4044 - categorical_accuracy: 0.8307 - val_loss: 0.3890 - val_categorical_accuracy: 0.8490\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4061 - categorical_accuracy: 0.8330 - val_loss: 0.4364 - val_categorical_accuracy: 0.8229\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3972 - categorical_accuracy: 0.8429 - val_loss: 0.3881 - val_categorical_accuracy: 0.8594\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4026 - categorical_accuracy: 0.8313 - val_loss: 0.3857 - val_categorical_accuracy: 0.8646\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4093 - categorical_accuracy: 0.8301 - val_loss: 0.3875 - val_categorical_accuracy: 0.8490\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3969 - categorical_accuracy: 0.8319 - val_loss: 0.4107 - val_categorical_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3910 - categorical_accuracy: 0.8452 - val_loss: 0.3795 - val_categorical_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3918 - categorical_accuracy: 0.8452 - val_loss: 0.3963 - val_categorical_accuracy: 0.8438\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3956 - categorical_accuracy: 0.8400 - val_loss: 0.4082 - val_categorical_accuracy: 0.8281\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4029 - categorical_accuracy: 0.8284 - val_loss: 0.4088 - val_categorical_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3998 - categorical_accuracy: 0.8388 - val_loss: 0.3786 - val_categorical_accuracy: 0.8594\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3998 - categorical_accuracy: 0.8371 - val_loss: 0.3583 - val_categorical_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3917 - categorical_accuracy: 0.8388 - val_loss: 0.3774 - val_categorical_accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3953 - categorical_accuracy: 0.8400 - val_loss: 0.3873 - val_categorical_accuracy: 0.8490\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3824 - categorical_accuracy: 0.8458 - val_loss: 0.4058 - val_categorical_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3996 - categorical_accuracy: 0.8284 - val_loss: 0.4421 - val_categorical_accuracy: 0.8021\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3817 - categorical_accuracy: 0.8441 - val_loss: 0.3782 - val_categorical_accuracy: 0.8490\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3999 - categorical_accuracy: 0.8336 - val_loss: 0.3855 - val_categorical_accuracy: 0.8646\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4015 - categorical_accuracy: 0.8261 - val_loss: 0.4520 - val_categorical_accuracy: 0.7969\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3981 - categorical_accuracy: 0.8319 - val_loss: 0.3840 - val_categorical_accuracy: 0.8490\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3983 - categorical_accuracy: 0.8278 - val_loss: 0.3579 - val_categorical_accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3801 - categorical_accuracy: 0.8441 - val_loss: 0.3593 - val_categorical_accuracy: 0.8542\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3923 - categorical_accuracy: 0.8388 - val_loss: 0.4802 - val_categorical_accuracy: 0.7552\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3970 - categorical_accuracy: 0.8330 - val_loss: 0.3618 - val_categorical_accuracy: 0.8646\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3886 - categorical_accuracy: 0.8383 - val_loss: 0.3770 - val_categorical_accuracy: 0.8438\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3857 - categorical_accuracy: 0.8319 - val_loss: 0.3621 - val_categorical_accuracy: 0.8802\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3815 - categorical_accuracy: 0.8452 - val_loss: 0.3737 - val_categorical_accuracy: 0.8594\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3988 - categorical_accuracy: 0.8365 - val_loss: 0.4051 - val_categorical_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3805 - categorical_accuracy: 0.8435 - val_loss: 0.5219 - val_categorical_accuracy: 0.7448\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3903 - categorical_accuracy: 0.8348 - val_loss: 0.4129 - val_categorical_accuracy: 0.8229\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3736 - categorical_accuracy: 0.8441 - val_loss: 0.3655 - val_categorical_accuracy: 0.8490\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3891 - categorical_accuracy: 0.8365 - val_loss: 0.3614 - val_categorical_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3797 - categorical_accuracy: 0.8365 - val_loss: 0.3672 - val_categorical_accuracy: 0.8698\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3842 - categorical_accuracy: 0.8423 - val_loss: 0.3933 - val_categorical_accuracy: 0.8281\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3795 - categorical_accuracy: 0.8435 - val_loss: 0.3666 - val_categorical_accuracy: 0.8698\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3887 - categorical_accuracy: 0.8342 - val_loss: 0.4074 - val_categorical_accuracy: 0.8281\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3795 - categorical_accuracy: 0.8406 - val_loss: 0.3573 - val_categorical_accuracy: 0.8646\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3788 - categorical_accuracy: 0.8365 - val_loss: 0.3549 - val_categorical_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3813 - categorical_accuracy: 0.8383 - val_loss: 0.3806 - val_categorical_accuracy: 0.8542\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3864 - categorical_accuracy: 0.8301 - val_loss: 0.3914 - val_categorical_accuracy: 0.8542\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3824 - categorical_accuracy: 0.8371 - val_loss: 0.3707 - val_categorical_accuracy: 0.8542\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3676 - categorical_accuracy: 0.8516 - val_loss: 0.3732 - val_categorical_accuracy: 0.8542\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3828 - categorical_accuracy: 0.8429 - val_loss: 0.3583 - val_categorical_accuracy: 0.8802\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3827 - categorical_accuracy: 0.8446 - val_loss: 0.4341 - val_categorical_accuracy: 0.7969\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3799 - categorical_accuracy: 0.8400 - val_loss: 0.5524 - val_categorical_accuracy: 0.7344\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3882 - categorical_accuracy: 0.8388 - val_loss: 0.3899 - val_categorical_accuracy: 0.8542\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3840 - categorical_accuracy: 0.8342 - val_loss: 0.3485 - val_categorical_accuracy: 0.8594\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3853 - categorical_accuracy: 0.8400 - val_loss: 0.4111 - val_categorical_accuracy: 0.8177\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3777 - categorical_accuracy: 0.8452 - val_loss: 0.3879 - val_categorical_accuracy: 0.8385\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3774 - categorical_accuracy: 0.8429 - val_loss: 0.3680 - val_categorical_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3856 - categorical_accuracy: 0.8348 - val_loss: 0.3816 - val_categorical_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3786 - categorical_accuracy: 0.8452 - val_loss: 0.4273 - val_categorical_accuracy: 0.7969\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3689 - categorical_accuracy: 0.8446 - val_loss: 0.4042 - val_categorical_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3887 - categorical_accuracy: 0.8336 - val_loss: 0.3455 - val_categorical_accuracy: 0.8646\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3714 - categorical_accuracy: 0.8510 - val_loss: 0.3602 - val_categorical_accuracy: 0.8698\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3830 - categorical_accuracy: 0.8348 - val_loss: 0.3947 - val_categorical_accuracy: 0.8385\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3782 - categorical_accuracy: 0.8406 - val_loss: 0.3620 - val_categorical_accuracy: 0.8490\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3813 - categorical_accuracy: 0.8452 - val_loss: 0.4595 - val_categorical_accuracy: 0.7865\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3862 - categorical_accuracy: 0.8400 - val_loss: 0.3489 - val_categorical_accuracy: 0.8698\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3831 - categorical_accuracy: 0.8278 - val_loss: 0.3641 - val_categorical_accuracy: 0.8646\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3688 - categorical_accuracy: 0.8423 - val_loss: 0.3532 - val_categorical_accuracy: 0.8594\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3723 - categorical_accuracy: 0.8412 - val_loss: 0.3602 - val_categorical_accuracy: 0.8490\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4013 - categorical_accuracy: 0.8296 - val_loss: 0.3506 - val_categorical_accuracy: 0.8802\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3750 - categorical_accuracy: 0.8435 - val_loss: 0.3851 - val_categorical_accuracy: 0.8438\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3767 - categorical_accuracy: 0.8388 - val_loss: 0.3827 - val_categorical_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3836 - categorical_accuracy: 0.8441 - val_loss: 0.5253 - val_categorical_accuracy: 0.7396\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3790 - categorical_accuracy: 0.8406 - val_loss: 0.4399 - val_categorical_accuracy: 0.8073\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3779 - categorical_accuracy: 0.8435 - val_loss: 0.3641 - val_categorical_accuracy: 0.8542\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3667 - categorical_accuracy: 0.8446 - val_loss: 0.4029 - val_categorical_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3737 - categorical_accuracy: 0.8429 - val_loss: 0.3767 - val_categorical_accuracy: 0.8385\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3556 - categorical_accuracy: 0.8597 - val_loss: 0.3589 - val_categorical_accuracy: 0.8646\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3647 - categorical_accuracy: 0.8499 - val_loss: 0.3693 - val_categorical_accuracy: 0.8646\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 32)             5376      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 22,437\n",
      "Trainable params: 22,245\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 6s 27ms/step - loss: 0.5619 - categorical_accuracy: 0.6986 - val_loss: 0.6922 - val_categorical_accuracy: 0.4583\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5007 - categorical_accuracy: 0.8052 - val_loss: 0.6963 - val_categorical_accuracy: 0.4583\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4905 - categorical_accuracy: 0.8046 - val_loss: 0.6910 - val_categorical_accuracy: 0.4635\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.4899 - categorical_accuracy: 0.8191 - val_loss: 0.6774 - val_categorical_accuracy: 0.5208\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4803 - categorical_accuracy: 0.8180 - val_loss: 0.6570 - val_categorical_accuracy: 0.7188\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4616 - categorical_accuracy: 0.8394 - val_loss: 0.6092 - val_categorical_accuracy: 0.8698\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4693 - categorical_accuracy: 0.8226 - val_loss: 0.5639 - val_categorical_accuracy: 0.8646\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4725 - categorical_accuracy: 0.8122 - val_loss: 0.5062 - val_categorical_accuracy: 0.8698\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4528 - categorical_accuracy: 0.8255 - val_loss: 0.4660 - val_categorical_accuracy: 0.8646\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4518 - categorical_accuracy: 0.8162 - val_loss: 0.4391 - val_categorical_accuracy: 0.8698\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4567 - categorical_accuracy: 0.8214 - val_loss: 0.4154 - val_categorical_accuracy: 0.8698\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4377 - categorical_accuracy: 0.8359 - val_loss: 0.4103 - val_categorical_accuracy: 0.8594\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4503 - categorical_accuracy: 0.8191 - val_loss: 0.4038 - val_categorical_accuracy: 0.8594\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4347 - categorical_accuracy: 0.8354 - val_loss: 0.4093 - val_categorical_accuracy: 0.8646\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4490 - categorical_accuracy: 0.8186 - val_loss: 0.3863 - val_categorical_accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4267 - categorical_accuracy: 0.8325 - val_loss: 0.3821 - val_categorical_accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4266 - categorical_accuracy: 0.8319 - val_loss: 0.4020 - val_categorical_accuracy: 0.8698\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4465 - categorical_accuracy: 0.8209 - val_loss: 0.4067 - val_categorical_accuracy: 0.8490\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4230 - categorical_accuracy: 0.8272 - val_loss: 0.3799 - val_categorical_accuracy: 0.8802\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4176 - categorical_accuracy: 0.8400 - val_loss: 0.3869 - val_categorical_accuracy: 0.8698\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4201 - categorical_accuracy: 0.8348 - val_loss: 0.3692 - val_categorical_accuracy: 0.8698\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4193 - categorical_accuracy: 0.8359 - val_loss: 0.3612 - val_categorical_accuracy: 0.8906\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4159 - categorical_accuracy: 0.8359 - val_loss: 0.3786 - val_categorical_accuracy: 0.8698\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4156 - categorical_accuracy: 0.8325 - val_loss: 0.3573 - val_categorical_accuracy: 0.8854\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4220 - categorical_accuracy: 0.8272 - val_loss: 0.3694 - val_categorical_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4006 - categorical_accuracy: 0.8423 - val_loss: 0.3499 - val_categorical_accuracy: 0.8906\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4043 - categorical_accuracy: 0.8377 - val_loss: 0.3507 - val_categorical_accuracy: 0.8906\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4224 - categorical_accuracy: 0.8209 - val_loss: 0.3669 - val_categorical_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4100 - categorical_accuracy: 0.8301 - val_loss: 0.3417 - val_categorical_accuracy: 0.8854\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4128 - categorical_accuracy: 0.8278 - val_loss: 0.3890 - val_categorical_accuracy: 0.8490\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4216 - categorical_accuracy: 0.8232 - val_loss: 0.3394 - val_categorical_accuracy: 0.9115\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3838 - categorical_accuracy: 0.8528 - val_loss: 0.4246 - val_categorical_accuracy: 0.8073\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3878 - categorical_accuracy: 0.8504 - val_loss: 0.3381 - val_categorical_accuracy: 0.8854\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4073 - categorical_accuracy: 0.8319 - val_loss: 0.3381 - val_categorical_accuracy: 0.9062\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4105 - categorical_accuracy: 0.8342 - val_loss: 0.3398 - val_categorical_accuracy: 0.8854\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4039 - categorical_accuracy: 0.8249 - val_loss: 0.3521 - val_categorical_accuracy: 0.8646\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3964 - categorical_accuracy: 0.8377 - val_loss: 0.3996 - val_categorical_accuracy: 0.8281\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4023 - categorical_accuracy: 0.8290 - val_loss: 0.3313 - val_categorical_accuracy: 0.9062\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4032 - categorical_accuracy: 0.8272 - val_loss: 0.3321 - val_categorical_accuracy: 0.9115\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4015 - categorical_accuracy: 0.8400 - val_loss: 0.3441 - val_categorical_accuracy: 0.8854\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4032 - categorical_accuracy: 0.8278 - val_loss: 0.3212 - val_categorical_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3971 - categorical_accuracy: 0.8377 - val_loss: 0.3446 - val_categorical_accuracy: 0.8854\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3797 - categorical_accuracy: 0.8516 - val_loss: 0.3456 - val_categorical_accuracy: 0.8698\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3956 - categorical_accuracy: 0.83 - 0s 5ms/step - loss: 0.3995 - categorical_accuracy: 0.8272 - val_loss: 0.3243 - val_categorical_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3935 - categorical_accuracy: 0.8371 - val_loss: 0.3141 - val_categorical_accuracy: 0.9010\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3937 - categorical_accuracy: 0.8388 - val_loss: 0.3327 - val_categorical_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3960 - categorical_accuracy: 0.8388 - val_loss: 0.3362 - val_categorical_accuracy: 0.8906\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3996 - categorical_accuracy: 0.8301 - val_loss: 0.3257 - val_categorical_accuracy: 0.8802\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3688 - categorical_accuracy: 0.8481 - val_loss: 0.3189 - val_categorical_accuracy: 0.8958\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3878 - categorical_accuracy: 0.8429 - val_loss: 0.3365 - val_categorical_accuracy: 0.8958\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3820 - categorical_accuracy: 0.8441 - val_loss: 0.3763 - val_categorical_accuracy: 0.8438\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3839 - categorical_accuracy: 0.8365 - val_loss: 0.3646 - val_categorical_accuracy: 0.8385\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3812 - categorical_accuracy: 0.8452 - val_loss: 0.3061 - val_categorical_accuracy: 0.8906\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3885 - categorical_accuracy: 0.8377 - val_loss: 0.3721 - val_categorical_accuracy: 0.8542\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3951 - categorical_accuracy: 0.8342 - val_loss: 0.3223 - val_categorical_accuracy: 0.8958\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3875 - categorical_accuracy: 0.8354 - val_loss: 0.3144 - val_categorical_accuracy: 0.8906\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3993 - categorical_accuracy: 0.8284 - val_loss: 0.3218 - val_categorical_accuracy: 0.8854\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3966 - categorical_accuracy: 0.8267 - val_loss: 0.3197 - val_categorical_accuracy: 0.8854\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3894 - categorical_accuracy: 0.8365 - val_loss: 0.3006 - val_categorical_accuracy: 0.8854\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3973 - categorical_accuracy: 0.8307 - val_loss: 0.3318 - val_categorical_accuracy: 0.8750\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3767 - categorical_accuracy: 0.8412 - val_loss: 0.2972 - val_categorical_accuracy: 0.9115\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3797 - categorical_accuracy: 0.8371 - val_loss: 0.3839 - val_categorical_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4118 - categorical_accuracy: 0.8278 - val_loss: 0.3266 - val_categorical_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3696 - categorical_accuracy: 0.8493 - val_loss: 0.3415 - val_categorical_accuracy: 0.8646\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4028 - categorical_accuracy: 0.8272 - val_loss: 0.3243 - val_categorical_accuracy: 0.9010\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3695 - categorical_accuracy: 0.8522 - val_loss: 0.4327 - val_categorical_accuracy: 0.8021\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3796 - categorical_accuracy: 0.8377 - val_loss: 0.3056 - val_categorical_accuracy: 0.8854\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3895 - categorical_accuracy: 0.8336 - val_loss: 0.3413 - val_categorical_accuracy: 0.8542\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3818 - categorical_accuracy: 0.8522 - val_loss: 0.2970 - val_categorical_accuracy: 0.8802\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3741 - categorical_accuracy: 0.83 - 0s 5ms/step - loss: 0.3770 - categorical_accuracy: 0.8342 - val_loss: 0.3056 - val_categorical_accuracy: 0.8854\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3782 - categorical_accuracy: 0.8481 - val_loss: 0.2946 - val_categorical_accuracy: 0.8906\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3901 - categorical_accuracy: 0.8359 - val_loss: 0.3271 - val_categorical_accuracy: 0.8958\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3860 - categorical_accuracy: 0.8336 - val_loss: 0.3388 - val_categorical_accuracy: 0.8646\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3706 - categorical_accuracy: 0.8493 - val_loss: 0.3131 - val_categorical_accuracy: 0.8854\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3759 - categorical_accuracy: 0.8412 - val_loss: 0.3019 - val_categorical_accuracy: 0.8958\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3845 - categorical_accuracy: 0.8365 - val_loss: 0.3468 - val_categorical_accuracy: 0.8542\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3839 - categorical_accuracy: 0.8336 - val_loss: 0.3349 - val_categorical_accuracy: 0.8698\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3720 - categorical_accuracy: 0.8400 - val_loss: 0.3408 - val_categorical_accuracy: 0.8698\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3900 - categorical_accuracy: 0.8441 - val_loss: 0.3117 - val_categorical_accuracy: 0.8906\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3950 - categorical_accuracy: 0.8330 - val_loss: 0.3863 - val_categorical_accuracy: 0.8281\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3765 - categorical_accuracy: 0.8470 - val_loss: 0.4194 - val_categorical_accuracy: 0.7812\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3837 - categorical_accuracy: 0.8394 - val_loss: 0.3298 - val_categorical_accuracy: 0.8698\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3897 - categorical_accuracy: 0.8336 - val_loss: 0.3370 - val_categorical_accuracy: 0.8750\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3819 - categorical_accuracy: 0.8371 - val_loss: 0.3022 - val_categorical_accuracy: 0.8854\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3843 - categorical_accuracy: 0.8388 - val_loss: 0.2922 - val_categorical_accuracy: 0.9062\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3855 - categorical_accuracy: 0.8394 - val_loss: 0.3039 - val_categorical_accuracy: 0.8906\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3668 - categorical_accuracy: 0.8458 - val_loss: 0.3459 - val_categorical_accuracy: 0.8646\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3803 - categorical_accuracy: 0.8412 - val_loss: 0.4085 - val_categorical_accuracy: 0.8229\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3802 - categorical_accuracy: 0.8348 - val_loss: 0.3239 - val_categorical_accuracy: 0.8490\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3549 - categorical_accuracy: 0.8626 - val_loss: 0.2889 - val_categorical_accuracy: 0.9010\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3865 - categorical_accuracy: 0.8325 - val_loss: 0.3903 - val_categorical_accuracy: 0.8281\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3695 - categorical_accuracy: 0.8528 - val_loss: 0.2961 - val_categorical_accuracy: 0.8802\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3867 - categorical_accuracy: 0.8383 - val_loss: 0.3285 - val_categorical_accuracy: 0.8542\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3810 - categorical_accuracy: 0.8388 - val_loss: 0.2941 - val_categorical_accuracy: 0.8854\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3866 - categorical_accuracy: 0.8377 - val_loss: 0.2986 - val_categorical_accuracy: 0.8906\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3796 - categorical_accuracy: 0.8359 - val_loss: 0.2963 - val_categorical_accuracy: 0.9219\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3646 - categorical_accuracy: 0.8528 - val_loss: 0.2929 - val_categorical_accuracy: 0.9010\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3819 - categorical_accuracy: 0.8365 - val_loss: 0.2913 - val_categorical_accuracy: 0.8958\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3848 - categorical_accuracy: 0.8359 - val_loss: 0.3851 - val_categorical_accuracy: 0.8229\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3957 - categorical_accuracy: 0.8290 - val_loss: 0.3397 - val_categorical_accuracy: 0.8594\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 64)             18944     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 85,829\n",
      "Trainable params: 85,445\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 6s 23ms/step - loss: 0.7038 - categorical_accuracy: 0.5757 - val_loss: 0.6914 - val_categorical_accuracy: 0.5729\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6899 - categorical_accuracy: 0.5757 - val_loss: 0.6898 - val_categorical_accuracy: 0.5729\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6859 - categorical_accuracy: 0.5757 - val_loss: 0.6882 - val_categorical_accuracy: 0.5729\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6830 - categorical_accuracy: 0.5757 - val_loss: 0.6873 - val_categorical_accuracy: 0.5729\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6755 - categorical_accuracy: 0.5757 - val_loss: 0.6868 - val_categorical_accuracy: 0.5729\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6654 - categorical_accuracy: 0.5757 - val_loss: 0.6867 - val_categorical_accuracy: 0.5729\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6548 - categorical_accuracy: 0.5757 - val_loss: 0.6863 - val_categorical_accuracy: 0.5729\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6425 - categorical_accuracy: 0.5757 - val_loss: 0.6809 - val_categorical_accuracy: 0.5729\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6313 - categorical_accuracy: 0.5757 - val_loss: 0.6532 - val_categorical_accuracy: 0.5729\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6241 - categorical_accuracy: 0.5757 - val_loss: 0.6225 - val_categorical_accuracy: 0.5729\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6147 - categorical_accuracy: 0.5757 - val_loss: 0.5812 - val_categorical_accuracy: 0.5729\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6028 - categorical_accuracy: 0.5757 - val_loss: 0.6057 - val_categorical_accuracy: 0.5729\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5876 - categorical_accuracy: 0.5757 - val_loss: 0.5957 - val_categorical_accuracy: 0.5729\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5769 - categorical_accuracy: 0.5757 - val_loss: 0.5723 - val_categorical_accuracy: 0.5729\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5619 - categorical_accuracy: 0.5757 - val_loss: 0.5208 - val_categorical_accuracy: 0.5729\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5555 - categorical_accuracy: 0.7443 - val_loss: 0.5194 - val_categorical_accuracy: 0.8646\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5255 - categorical_accuracy: 0.8429 - val_loss: 0.5356 - val_categorical_accuracy: 0.8125\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5239 - categorical_accuracy: 0.8284 - val_loss: 0.4759 - val_categorical_accuracy: 0.8802\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5076 - categorical_accuracy: 0.8261 - val_loss: 0.4666 - val_categorical_accuracy: 0.8698\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5068 - categorical_accuracy: 0.8133 - val_loss: 0.4500 - val_categorical_accuracy: 0.8646\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4916 - categorical_accuracy: 0.8220 - val_loss: 0.4505 - val_categorical_accuracy: 0.8698\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4972 - categorical_accuracy: 0.8220 - val_loss: 0.4262 - val_categorical_accuracy: 0.8698\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4800 - categorical_accuracy: 0.8272 - val_loss: 0.4265 - val_categorical_accuracy: 0.8646\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4671 - categorical_accuracy: 0.8336 - val_loss: 0.4142 - val_categorical_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4652 - categorical_accuracy: 0.8354 - val_loss: 0.4027 - val_categorical_accuracy: 0.8802\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4576 - categorical_accuracy: 0.8325 - val_loss: 0.4143 - val_categorical_accuracy: 0.8542\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4680 - categorical_accuracy: 0.8122 - val_loss: 0.3906 - val_categorical_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4426 - categorical_accuracy: 0.8412 - val_loss: 0.3851 - val_categorical_accuracy: 0.8698\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4500 - categorical_accuracy: 0.8186 - val_loss: 0.4123 - val_categorical_accuracy: 0.8542\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4318 - categorical_accuracy: 0.8406 - val_loss: 0.4091 - val_categorical_accuracy: 0.8646\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4328 - categorical_accuracy: 0.8325 - val_loss: 0.3687 - val_categorical_accuracy: 0.8698\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4397 - categorical_accuracy: 0.8307 - val_loss: 0.3614 - val_categorical_accuracy: 0.8802\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4350 - categorical_accuracy: 0.8354 - val_loss: 0.3650 - val_categorical_accuracy: 0.8802\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4276 - categorical_accuracy: 0.8348 - val_loss: 0.3727 - val_categorical_accuracy: 0.8594\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4253 - categorical_accuracy: 0.8272 - val_loss: 0.3577 - val_categorical_accuracy: 0.8802\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4198 - categorical_accuracy: 0.8243 - val_loss: 0.3514 - val_categorical_accuracy: 0.8802\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4199 - categorical_accuracy: 0.8371 - val_loss: 0.4052 - val_categorical_accuracy: 0.8385\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4117 - categorical_accuracy: 0.8388 - val_loss: 0.3464 - val_categorical_accuracy: 0.8906\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4121 - categorical_accuracy: 0.8301 - val_loss: 0.3472 - val_categorical_accuracy: 0.8646\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4137 - categorical_accuracy: 0.8261 - val_loss: 0.3403 - val_categorical_accuracy: 0.8958\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4133 - categorical_accuracy: 0.8255 - val_loss: 0.3907 - val_categorical_accuracy: 0.8438\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4091 - categorical_accuracy: 0.8296 - val_loss: 0.3450 - val_categorical_accuracy: 0.8854\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4098 - categorical_accuracy: 0.8307 - val_loss: 0.3577 - val_categorical_accuracy: 0.8698\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4279 - categorical_accuracy: 0.8203 - val_loss: 0.3544 - val_categorical_accuracy: 0.8698\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4155 - categorical_accuracy: 0.8284 - val_loss: 0.3391 - val_categorical_accuracy: 0.8854\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4010 - categorical_accuracy: 0.8383 - val_loss: 0.3430 - val_categorical_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4087 - categorical_accuracy: 0.8359 - val_loss: 0.3283 - val_categorical_accuracy: 0.8802\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3908 - categorical_accuracy: 0.8400 - val_loss: 0.3396 - val_categorical_accuracy: 0.8802\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3955 - categorical_accuracy: 0.8371 - val_loss: 0.3244 - val_categorical_accuracy: 0.8854\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3930 - categorical_accuracy: 0.8452 - val_loss: 0.3246 - val_categorical_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4252 - categorical_accuracy: 0.8168 - val_loss: 0.3498 - val_categorical_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3981 - categorical_accuracy: 0.8371 - val_loss: 0.3238 - val_categorical_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4104 - categorical_accuracy: 0.8319 - val_loss: 0.3357 - val_categorical_accuracy: 0.8802\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3993 - categorical_accuracy: 0.8272 - val_loss: 0.3180 - val_categorical_accuracy: 0.8802\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3995 - categorical_accuracy: 0.8284 - val_loss: 0.3210 - val_categorical_accuracy: 0.8698\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3970 - categorical_accuracy: 0.8330 - val_loss: 0.3190 - val_categorical_accuracy: 0.8854\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3987 - categorical_accuracy: 0.8417 - val_loss: 0.3221 - val_categorical_accuracy: 0.8854\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3886 - categorical_accuracy: 0.8371 - val_loss: 0.3244 - val_categorical_accuracy: 0.8698\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3835 - categorical_accuracy: 0.8493 - val_loss: 0.3255 - val_categorical_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3953 - categorical_accuracy: 0.8261 - val_loss: 0.3115 - val_categorical_accuracy: 0.8802\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3877 - categorical_accuracy: 0.8388 - val_loss: 0.3081 - val_categorical_accuracy: 0.8854\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3908 - categorical_accuracy: 0.8342 - val_loss: 0.3271 - val_categorical_accuracy: 0.8854\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3955 - categorical_accuracy: 0.8365 - val_loss: 0.3851 - val_categorical_accuracy: 0.8490\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3812 - categorical_accuracy: 0.8435 - val_loss: 0.4295 - val_categorical_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3877 - categorical_accuracy: 0.8400 - val_loss: 0.3682 - val_categorical_accuracy: 0.8490\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3742 - categorical_accuracy: 0.8475 - val_loss: 0.3378 - val_categorical_accuracy: 0.8542\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4040 - categorical_accuracy: 0.8255 - val_loss: 0.4494 - val_categorical_accuracy: 0.7917\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3781 - categorical_accuracy: 0.8400 - val_loss: 0.3259 - val_categorical_accuracy: 0.8698\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3814 - categorical_accuracy: 0.8452 - val_loss: 0.3100 - val_categorical_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3884 - categorical_accuracy: 0.8296 - val_loss: 0.3160 - val_categorical_accuracy: 0.8802\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3736 - categorical_accuracy: 0.8441 - val_loss: 0.3165 - val_categorical_accuracy: 0.8802\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4035 - categorical_accuracy: 0.8290 - val_loss: 0.3068 - val_categorical_accuracy: 0.8854\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3760 - categorical_accuracy: 0.8458 - val_loss: 0.3286 - val_categorical_accuracy: 0.8802\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3819 - categorical_accuracy: 0.8365 - val_loss: 0.3176 - val_categorical_accuracy: 0.8854\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3961 - categorical_accuracy: 0.8307 - val_loss: 0.4705 - val_categorical_accuracy: 0.7656\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3876 - categorical_accuracy: 0.8417 - val_loss: 0.3476 - val_categorical_accuracy: 0.8646\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3869 - categorical_accuracy: 0.8336 - val_loss: 0.3206 - val_categorical_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3852 - categorical_accuracy: 0.8342 - val_loss: 0.3281 - val_categorical_accuracy: 0.8646\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3882 - categorical_accuracy: 0.8371 - val_loss: 0.3174 - val_categorical_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3822 - categorical_accuracy: 0.8417 - val_loss: 0.3124 - val_categorical_accuracy: 0.8646\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3864 - categorical_accuracy: 0.8400 - val_loss: 0.3106 - val_categorical_accuracy: 0.8646\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3914 - categorical_accuracy: 0.8388 - val_loss: 0.3159 - val_categorical_accuracy: 0.8750\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3945 - categorical_accuracy: 0.8261 - val_loss: 0.3109 - val_categorical_accuracy: 0.8802\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3869 - categorical_accuracy: 0.8313 - val_loss: 0.3273 - val_categorical_accuracy: 0.8698\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3716 - categorical_accuracy: 0.8394 - val_loss: 0.3134 - val_categorical_accuracy: 0.8854\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3920 - categorical_accuracy: 0.8371 - val_loss: 0.3177 - val_categorical_accuracy: 0.8750\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3837 - categorical_accuracy: 0.8429 - val_loss: 0.3111 - val_categorical_accuracy: 0.8802\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3889 - categorical_accuracy: 0.8365 - val_loss: 0.2971 - val_categorical_accuracy: 0.8802\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3868 - categorical_accuracy: 0.8342 - val_loss: 0.3152 - val_categorical_accuracy: 0.8906\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3566 - categorical_accuracy: 0.8574 - val_loss: 0.3026 - val_categorical_accuracy: 0.8802\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3901 - categorical_accuracy: 0.8336 - val_loss: 0.3059 - val_categorical_accuracy: 0.8802\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3860 - categorical_accuracy: 0.8377 - val_loss: 0.4189 - val_categorical_accuracy: 0.8125\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3895 - categorical_accuracy: 0.8342 - val_loss: 0.4023 - val_categorical_accuracy: 0.8229\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3724 - categorical_accuracy: 0.8417 - val_loss: 0.3243 - val_categorical_accuracy: 0.8698\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3884 - categorical_accuracy: 0.8290 - val_loss: 0.3177 - val_categorical_accuracy: 0.8698\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3810 - categorical_accuracy: 0.8359 - val_loss: 0.3056 - val_categorical_accuracy: 0.8854\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3745 - categorical_accuracy: 0.8446 - val_loss: 0.3263 - val_categorical_accuracy: 0.8646\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3929 - categorical_accuracy: 0.8307 - val_loss: 0.3461 - val_categorical_accuracy: 0.8490\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3822 - categorical_accuracy: 0.8342 - val_loss: 0.3056 - val_categorical_accuracy: 0.8698\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3736 - categorical_accuracy: 0.8417 - val_loss: 0.3035 - val_categorical_accuracy: 0.8854\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 128)            70656     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 335,493\n",
      "Trainable params: 334,725\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 6s 25ms/step - loss: 0.5454 - categorical_accuracy: 0.7913 - val_loss: 0.6939 - val_categorical_accuracy: 0.4792\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.5315 - categorical_accuracy: 0.7861 - val_loss: 0.6949 - val_categorical_accuracy: 0.4792\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5105 - categorical_accuracy: 0.8029 - val_loss: 0.6964 - val_categorical_accuracy: 0.4792\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5059 - categorical_accuracy: 0.7936 - val_loss: 0.6977 - val_categorical_accuracy: 0.4792\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.5032 - categorical_accuracy: 0.8000 - val_loss: 0.6957 - val_categorical_accuracy: 0.4948\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4951 - categorical_accuracy: 0.8116 - val_loss: 0.6624 - val_categorical_accuracy: 0.6302\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4801 - categorical_accuracy: 0.8012 - val_loss: 0.5738 - val_categorical_accuracy: 0.8281\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4753 - categorical_accuracy: 0.8238 - val_loss: 0.5550 - val_categorical_accuracy: 0.8229\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.4812 - categorical_accuracy: 0.8052 - val_loss: 0.4826 - val_categorical_accuracy: 0.8438\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4706 - categorical_accuracy: 0.8174 - val_loss: 0.4601 - val_categorical_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4579 - categorical_accuracy: 0.8174 - val_loss: 0.4328 - val_categorical_accuracy: 0.8958\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4717 - categorical_accuracy: 0.8029 - val_loss: 0.4314 - val_categorical_accuracy: 0.8854\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4483 - categorical_accuracy: 0.8267 - val_loss: 0.4259 - val_categorical_accuracy: 0.8646\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4447 - categorical_accuracy: 0.8197 - val_loss: 0.4326 - val_categorical_accuracy: 0.8438\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.4419 - categorical_accuracy: 0.8272 - val_loss: 0.4290 - val_categorical_accuracy: 0.8646\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4358 - categorical_accuracy: 0.8354 - val_loss: 0.4337 - val_categorical_accuracy: 0.8229\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4399 - categorical_accuracy: 0.8272 - val_loss: 0.4022 - val_categorical_accuracy: 0.8594\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4357 - categorical_accuracy: 0.8301 - val_loss: 0.4000 - val_categorical_accuracy: 0.8542\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4403 - categorical_accuracy: 0.8243 - val_loss: 0.4014 - val_categorical_accuracy: 0.8594\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4244 - categorical_accuracy: 0.8371 - val_loss: 0.4000 - val_categorical_accuracy: 0.8802\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4279 - categorical_accuracy: 0.8278 - val_loss: 0.4015 - val_categorical_accuracy: 0.8594\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4184 - categorical_accuracy: 0.8394 - val_loss: 0.3938 - val_categorical_accuracy: 0.8490\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4084 - categorical_accuracy: 0.8417 - val_loss: 0.3905 - val_categorical_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.4225 - categorical_accuracy: 0.8284 - val_loss: 0.4009 - val_categorical_accuracy: 0.8542\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4098 - categorical_accuracy: 0.8400 - val_loss: 0.4046 - val_categorical_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4151 - categorical_accuracy: 0.8238 - val_loss: 0.3852 - val_categorical_accuracy: 0.8646\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4043 - categorical_accuracy: 0.8371 - val_loss: 0.4275 - val_categorical_accuracy: 0.8490\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4102 - categorical_accuracy: 0.8336 - val_loss: 0.3788 - val_categorical_accuracy: 0.8698\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4077 - categorical_accuracy: 0.8330 - val_loss: 0.3850 - val_categorical_accuracy: 0.8646\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3994 - categorical_accuracy: 0.8365 - val_loss: 0.4075 - val_categorical_accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4184 - categorical_accuracy: 0.8261 - val_loss: 0.3816 - val_categorical_accuracy: 0.8698\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4002 - categorical_accuracy: 0.8446 - val_loss: 0.3700 - val_categorical_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4102 - categorical_accuracy: 0.8348 - val_loss: 0.3681 - val_categorical_accuracy: 0.8646\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4051 - categorical_accuracy: 0.8348 - val_loss: 0.3935 - val_categorical_accuracy: 0.8594\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3988 - categorical_accuracy: 0.8365 - val_loss: 0.3916 - val_categorical_accuracy: 0.8646\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4042 - categorical_accuracy: 0.8278 - val_loss: 0.4258 - val_categorical_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4053 - categorical_accuracy: 0.8249 - val_loss: 0.4130 - val_categorical_accuracy: 0.8385\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4024 - categorical_accuracy: 0.8342 - val_loss: 0.4012 - val_categorical_accuracy: 0.8438\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3929 - categorical_accuracy: 0.8354 - val_loss: 0.4331 - val_categorical_accuracy: 0.8385\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4007 - categorical_accuracy: 0.8301 - val_loss: 0.3905 - val_categorical_accuracy: 0.8281\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4045 - categorical_accuracy: 0.8296 - val_loss: 0.3667 - val_categorical_accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3942 - categorical_accuracy: 0.8342 - val_loss: 0.3618 - val_categorical_accuracy: 0.8438\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3947 - categorical_accuracy: 0.8388 - val_loss: 0.3701 - val_categorical_accuracy: 0.8542\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4071 - categorical_accuracy: 0.8313 - val_loss: 0.3627 - val_categorical_accuracy: 0.8542\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3930 - categorical_accuracy: 0.8423 - val_loss: 0.3623 - val_categorical_accuracy: 0.8542\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3785 - categorical_accuracy: 0.8499 - val_loss: 0.3682 - val_categorical_accuracy: 0.8490\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3715 - categorical_accuracy: 0.8441 - val_loss: 0.3529 - val_categorical_accuracy: 0.8594\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3952 - categorical_accuracy: 0.8377 - val_loss: 0.3793 - val_categorical_accuracy: 0.8438\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3795 - categorical_accuracy: 0.8510 - val_loss: 0.3638 - val_categorical_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3954 - categorical_accuracy: 0.8307 - val_loss: 0.3582 - val_categorical_accuracy: 0.8698\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3935 - categorical_accuracy: 0.8371 - val_loss: 0.3501 - val_categorical_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3771 - categorical_accuracy: 0.85 - 0s 7ms/step - loss: 0.3850 - categorical_accuracy: 0.8493 - val_loss: 0.3647 - val_categorical_accuracy: 0.8490\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3882 - categorical_accuracy: 0.8330 - val_loss: 0.3718 - val_categorical_accuracy: 0.8385\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3889 - categorical_accuracy: 0.8429 - val_loss: 0.3571 - val_categorical_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3908 - categorical_accuracy: 0.8394 - val_loss: 0.3766 - val_categorical_accuracy: 0.8438\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3841 - categorical_accuracy: 0.8359 - val_loss: 0.3752 - val_categorical_accuracy: 0.8490\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3762 - categorical_accuracy: 0.8475 - val_loss: 0.3851 - val_categorical_accuracy: 0.8438\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3823 - categorical_accuracy: 0.8417 - val_loss: 0.3896 - val_categorical_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3883 - categorical_accuracy: 0.8371 - val_loss: 0.3522 - val_categorical_accuracy: 0.8594\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3914 - categorical_accuracy: 0.8307 - val_loss: 0.3603 - val_categorical_accuracy: 0.8438\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3901 - categorical_accuracy: 0.8365 - val_loss: 0.3550 - val_categorical_accuracy: 0.8490\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3793 - categorical_accuracy: 0.8406 - val_loss: 0.3424 - val_categorical_accuracy: 0.8750\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3738 - categorical_accuracy: 0.8441 - val_loss: 0.3673 - val_categorical_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3917 - categorical_accuracy: 0.8313 - val_loss: 0.3610 - val_categorical_accuracy: 0.8438\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3848 - categorical_accuracy: 0.8417 - val_loss: 0.3581 - val_categorical_accuracy: 0.8490\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3919 - categorical_accuracy: 0.8342 - val_loss: 0.3473 - val_categorical_accuracy: 0.8698\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3974 - categorical_accuracy: 0.8301 - val_loss: 0.3449 - val_categorical_accuracy: 0.8646\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3739 - categorical_accuracy: 0.8446 - val_loss: 0.4241 - val_categorical_accuracy: 0.8177\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4056 - categorical_accuracy: 0.8261 - val_loss: 0.3588 - val_categorical_accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3865 - categorical_accuracy: 0.8371 - val_loss: 0.3455 - val_categorical_accuracy: 0.8698\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3852 - categorical_accuracy: 0.8435 - val_loss: 0.3692 - val_categorical_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3858 - categorical_accuracy: 0.8330 - val_loss: 0.3576 - val_categorical_accuracy: 0.8542\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3807 - categorical_accuracy: 0.8499 - val_loss: 0.3639 - val_categorical_accuracy: 0.8490\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3784 - categorical_accuracy: 0.8342 - val_loss: 0.3607 - val_categorical_accuracy: 0.8594\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3885 - categorical_accuracy: 0.8354 - val_loss: 0.3554 - val_categorical_accuracy: 0.8438\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3880 - categorical_accuracy: 0.8354 - val_loss: 0.3735 - val_categorical_accuracy: 0.8385\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3837 - categorical_accuracy: 0.8417 - val_loss: 0.3657 - val_categorical_accuracy: 0.8281\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3902 - categorical_accuracy: 0.8371 - val_loss: 0.3805 - val_categorical_accuracy: 0.8281\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3881 - categorical_accuracy: 0.8325 - val_loss: 0.3345 - val_categorical_accuracy: 0.8542\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3742 - categorical_accuracy: 0.8464 - val_loss: 0.3484 - val_categorical_accuracy: 0.8490\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3820 - categorical_accuracy: 0.8359 - val_loss: 0.4161 - val_categorical_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3880 - categorical_accuracy: 0.8359 - val_loss: 0.3722 - val_categorical_accuracy: 0.8385\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4031 - categorical_accuracy: 0.8296 - val_loss: 0.3707 - val_categorical_accuracy: 0.8438\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3859 - categorical_accuracy: 0.8330 - val_loss: 0.3666 - val_categorical_accuracy: 0.8385\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3784 - categorical_accuracy: 0.8342 - val_loss: 0.3621 - val_categorical_accuracy: 0.8490\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3863 - categorical_accuracy: 0.8313 - val_loss: 0.3858 - val_categorical_accuracy: 0.8490\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3823 - categorical_accuracy: 0.8406 - val_loss: 0.3551 - val_categorical_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3686 - categorical_accuracy: 0.8481 - val_loss: 0.3803 - val_categorical_accuracy: 0.8385\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3820 - categorical_accuracy: 0.8348 - val_loss: 0.3421 - val_categorical_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3756 - categorical_accuracy: 0.8487 - val_loss: 0.3519 - val_categorical_accuracy: 0.8490\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3785 - categorical_accuracy: 0.8417 - val_loss: 0.3520 - val_categorical_accuracy: 0.8594\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3629 - categorical_accuracy: 0.8522 - val_loss: 0.3591 - val_categorical_accuracy: 0.8646\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3723 - categorical_accuracy: 0.8475 - val_loss: 0.3595 - val_categorical_accuracy: 0.8438\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3709 - categorical_accuracy: 0.8499 - val_loss: 0.3460 - val_categorical_accuracy: 0.8594\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3815 - categorical_accuracy: 0.8475 - val_loss: 0.3528 - val_categorical_accuracy: 0.8438\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3989 - categorical_accuracy: 0.8255 - val_loss: 0.3518 - val_categorical_accuracy: 0.8542\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.3749 - categorical_accuracy: 0.8330 - val_loss: 0.3642 - val_categorical_accuracy: 0.8594\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3843 - categorical_accuracy: 0.8406 - val_loss: 0.3729 - val_categorical_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3881 - categorical_accuracy: 0.8359 - val_loss: 0.3668 - val_categorical_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3644 - categorical_accuracy: 0.8475 - val_loss: 0.3724 - val_categorical_accuracy: 0.8333\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 1, 16)             1664      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 1, 16)             2112      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 1, 16)             2112      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1, 16)             64        \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 8,277\n",
      "Trainable params: 8,149\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 8s 29ms/step - loss: 0.6830 - categorical_accuracy: 0.7252 - val_loss: 0.6916 - val_categorical_accuracy: 0.5469\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6673 - categorical_accuracy: 0.7733 - val_loss: 0.6905 - val_categorical_accuracy: 0.5469\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6565 - categorical_accuracy: 0.8046 - val_loss: 0.6898 - val_categorical_accuracy: 0.5469\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6417 - categorical_accuracy: 0.8272 - val_loss: 0.6893 - val_categorical_accuracy: 0.5469\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6306 - categorical_accuracy: 0.8267 - val_loss: 0.6892 - val_categorical_accuracy: 0.5469\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6140 - categorical_accuracy: 0.8359 - val_loss: 0.6895 - val_categorical_accuracy: 0.5469\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6008 - categorical_accuracy: 0.8423 - val_loss: 0.6894 - val_categorical_accuracy: 0.5469\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5803 - categorical_accuracy: 0.8464 - val_loss: 0.6883 - val_categorical_accuracy: 0.5469\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5655 - categorical_accuracy: 0.8342 - val_loss: 0.6816 - val_categorical_accuracy: 0.5625\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5567 - categorical_accuracy: 0.8313 - val_loss: 0.6501 - val_categorical_accuracy: 0.6406\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5363 - categorical_accuracy: 0.8278 - val_loss: 0.5573 - val_categorical_accuracy: 0.8125\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5306 - categorical_accuracy: 0.8296 - val_loss: 0.6200 - val_categorical_accuracy: 0.6927\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5107 - categorical_accuracy: 0.8383 - val_loss: 0.5534 - val_categorical_accuracy: 0.7917\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4986 - categorical_accuracy: 0.8475 - val_loss: 0.5136 - val_categorical_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4870 - categorical_accuracy: 0.8464 - val_loss: 0.4495 - val_categorical_accuracy: 0.8802\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4771 - categorical_accuracy: 0.8481 - val_loss: 0.4963 - val_categorical_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4651 - categorical_accuracy: 0.8504 - val_loss: 0.4467 - val_categorical_accuracy: 0.8646\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4669 - categorical_accuracy: 0.8406 - val_loss: 0.5196 - val_categorical_accuracy: 0.8073\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4628 - categorical_accuracy: 0.8348 - val_loss: 0.4179 - val_categorical_accuracy: 0.8802\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4612 - categorical_accuracy: 0.8319 - val_loss: 0.4295 - val_categorical_accuracy: 0.8542\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4390 - categorical_accuracy: 0.8522 - val_loss: 0.4345 - val_categorical_accuracy: 0.8646\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4474 - categorical_accuracy: 0.8383 - val_loss: 0.4122 - val_categorical_accuracy: 0.8698\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4288 - categorical_accuracy: 0.8539 - val_loss: 0.4228 - val_categorical_accuracy: 0.8698\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4444 - categorical_accuracy: 0.8354 - val_loss: 0.4326 - val_categorical_accuracy: 0.8438\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4275 - categorical_accuracy: 0.8522 - val_loss: 0.4353 - val_categorical_accuracy: 0.8438\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4270 - categorical_accuracy: 0.8493 - val_loss: 0.5414 - val_categorical_accuracy: 0.7448\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4186 - categorical_accuracy: 0.8470 - val_loss: 0.3940 - val_categorical_accuracy: 0.8646\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4317 - categorical_accuracy: 0.8383 - val_loss: 0.3801 - val_categorical_accuracy: 0.8854\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4190 - categorical_accuracy: 0.8533 - val_loss: 0.3890 - val_categorical_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4206 - categorical_accuracy: 0.8400 - val_loss: 0.3786 - val_categorical_accuracy: 0.8698\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4028 - categorical_accuracy: 0.8493 - val_loss: 0.3915 - val_categorical_accuracy: 0.8542\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4019 - categorical_accuracy: 0.8568 - val_loss: 0.3772 - val_categorical_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4035 - categorical_accuracy: 0.8597 - val_loss: 0.3743 - val_categorical_accuracy: 0.8698\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4051 - categorical_accuracy: 0.8423 - val_loss: 0.3620 - val_categorical_accuracy: 0.8698\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3966 - categorical_accuracy: 0.8493 - val_loss: 0.3546 - val_categorical_accuracy: 0.8802\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4050 - categorical_accuracy: 0.8470 - val_loss: 0.3659 - val_categorical_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4032 - categorical_accuracy: 0.8533 - val_loss: 0.3561 - val_categorical_accuracy: 0.8802\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3935 - categorical_accuracy: 0.8458 - val_loss: 0.3616 - val_categorical_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3936 - categorical_accuracy: 0.8545 - val_loss: 0.3559 - val_categorical_accuracy: 0.8854\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4044 - categorical_accuracy: 0.8429 - val_loss: 0.3656 - val_categorical_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3941 - categorical_accuracy: 0.8487 - val_loss: 0.3879 - val_categorical_accuracy: 0.8438\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3944 - categorical_accuracy: 0.8446 - val_loss: 0.3778 - val_categorical_accuracy: 0.8542\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3878 - categorical_accuracy: 0.8516 - val_loss: 0.3530 - val_categorical_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3922 - categorical_accuracy: 0.8493 - val_loss: 0.3717 - val_categorical_accuracy: 0.8594\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3897 - categorical_accuracy: 0.8458 - val_loss: 0.5558 - val_categorical_accuracy: 0.8021\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3907 - categorical_accuracy: 0.8423 - val_loss: 0.3766 - val_categorical_accuracy: 0.8490\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3956 - categorical_accuracy: 0.8452 - val_loss: 0.3393 - val_categorical_accuracy: 0.8854\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3983 - categorical_accuracy: 0.8417 - val_loss: 0.3508 - val_categorical_accuracy: 0.8646\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4018 - categorical_accuracy: 0.8412 - val_loss: 0.3471 - val_categorical_accuracy: 0.8802\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3840 - categorical_accuracy: 0.8516 - val_loss: 0.3663 - val_categorical_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3842 - categorical_accuracy: 0.8510 - val_loss: 0.3328 - val_categorical_accuracy: 0.8854\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3955 - categorical_accuracy: 0.8365 - val_loss: 0.3853 - val_categorical_accuracy: 0.8438\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3882 - categorical_accuracy: 0.8475 - val_loss: 0.3491 - val_categorical_accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3852 - categorical_accuracy: 0.8499 - val_loss: 0.3293 - val_categorical_accuracy: 0.8958\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3800 - categorical_accuracy: 0.8493 - val_loss: 0.3485 - val_categorical_accuracy: 0.8698\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3612 - categorical_accuracy: 0.8643 - val_loss: 0.3428 - val_categorical_accuracy: 0.8854\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3774 - categorical_accuracy: 0.8458 - val_loss: 0.3308 - val_categorical_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3860 - categorical_accuracy: 0.8441 - val_loss: 0.3444 - val_categorical_accuracy: 0.8698\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3751 - categorical_accuracy: 0.8528 - val_loss: 0.3334 - val_categorical_accuracy: 0.8906\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3829 - categorical_accuracy: 0.8522 - val_loss: 0.3150 - val_categorical_accuracy: 0.8906\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3793 - categorical_accuracy: 0.8545 - val_loss: 0.3626 - val_categorical_accuracy: 0.8490\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3742 - categorical_accuracy: 0.8499 - val_loss: 0.3652 - val_categorical_accuracy: 0.8646\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3723 - categorical_accuracy: 0.8551 - val_loss: 0.3909 - val_categorical_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3930 - categorical_accuracy: 0.8400 - val_loss: 0.7547 - val_categorical_accuracy: 0.6927\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3891 - categorical_accuracy: 0.8446 - val_loss: 0.3584 - val_categorical_accuracy: 0.8750\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3782 - categorical_accuracy: 0.8528 - val_loss: 0.3262 - val_categorical_accuracy: 0.8854\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3753 - categorical_accuracy: 0.8470 - val_loss: 0.3285 - val_categorical_accuracy: 0.8854\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3699 - categorical_accuracy: 0.8568 - val_loss: 0.3299 - val_categorical_accuracy: 0.8906\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3747 - categorical_accuracy: 0.8510 - val_loss: 0.3431 - val_categorical_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3758 - categorical_accuracy: 0.8510 - val_loss: 0.3592 - val_categorical_accuracy: 0.8646\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3782 - categorical_accuracy: 0.8499 - val_loss: 0.3739 - val_categorical_accuracy: 0.8542\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3783 - categorical_accuracy: 0.8516 - val_loss: 0.3197 - val_categorical_accuracy: 0.8802\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3609 - categorical_accuracy: 0.8557 - val_loss: 0.3253 - val_categorical_accuracy: 0.8958\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3612 - categorical_accuracy: 0.8574 - val_loss: 0.3369 - val_categorical_accuracy: 0.8698\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3716 - categorical_accuracy: 0.8539 - val_loss: 0.3102 - val_categorical_accuracy: 0.8906\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3703 - categorical_accuracy: 0.8499 - val_loss: 0.3207 - val_categorical_accuracy: 0.8854\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3630 - categorical_accuracy: 0.8510 - val_loss: 0.3387 - val_categorical_accuracy: 0.8646\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3737 - categorical_accuracy: 0.8528 - val_loss: 0.3205 - val_categorical_accuracy: 0.8802\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3666 - categorical_accuracy: 0.8597 - val_loss: 0.3737 - val_categorical_accuracy: 0.8385\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3639 - categorical_accuracy: 0.8562 - val_loss: 0.3326 - val_categorical_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3832 - categorical_accuracy: 0.8487 - val_loss: 0.3433 - val_categorical_accuracy: 0.8542\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3756 - categorical_accuracy: 0.8423 - val_loss: 0.3720 - val_categorical_accuracy: 0.8490\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3767 - categorical_accuracy: 0.8487 - val_loss: 0.4785 - val_categorical_accuracy: 0.7969\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3759 - categorical_accuracy: 0.8481 - val_loss: 0.3498 - val_categorical_accuracy: 0.8646\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3669 - categorical_accuracy: 0.8493 - val_loss: 0.3276 - val_categorical_accuracy: 0.8854\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3684 - categorical_accuracy: 0.8504 - val_loss: 0.3779 - val_categorical_accuracy: 0.8490\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3753 - categorical_accuracy: 0.8429 - val_loss: 0.3480 - val_categorical_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3700 - categorical_accuracy: 0.8522 - val_loss: 0.3562 - val_categorical_accuracy: 0.8542\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3806 - categorical_accuracy: 0.8522 - val_loss: 0.3137 - val_categorical_accuracy: 0.8906\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3633 - categorical_accuracy: 0.8545 - val_loss: 0.3793 - val_categorical_accuracy: 0.8385\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3705 - categorical_accuracy: 0.8475 - val_loss: 0.3424 - val_categorical_accuracy: 0.8750\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3654 - categorical_accuracy: 0.8574 - val_loss: 0.3425 - val_categorical_accuracy: 0.8646\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3710 - categorical_accuracy: 0.8528 - val_loss: 0.3552 - val_categorical_accuracy: 0.8646\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3573 - categorical_accuracy: 0.8591 - val_loss: 0.3739 - val_categorical_accuracy: 0.8542\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3534 - categorical_accuracy: 0.8609 - val_loss: 0.4793 - val_categorical_accuracy: 0.8073\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3688 - categorical_accuracy: 0.8533 - val_loss: 0.3593 - val_categorical_accuracy: 0.8438\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3650 - categorical_accuracy: 0.8499 - val_loss: 0.3143 - val_categorical_accuracy: 0.8750\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3679 - categorical_accuracy: 0.8522 - val_loss: 0.3149 - val_categorical_accuracy: 0.8958\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3710 - categorical_accuracy: 0.8504 - val_loss: 0.3233 - val_categorical_accuracy: 0.8802\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3836 - categorical_accuracy: 0.8417 - val_loss: 0.4188 - val_categorical_accuracy: 0.8281\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 1, 32)             5376      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 1, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 1, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 30,885\n",
      "Trainable params: 30,629\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 8s 29ms/step - loss: 0.7012 - categorical_accuracy: 0.5757 - val_loss: 0.6922 - val_categorical_accuracy: 0.5417\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6864 - categorical_accuracy: 0.5762 - val_loss: 0.6914 - val_categorical_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6783 - categorical_accuracy: 0.5762 - val_loss: 0.6910 - val_categorical_accuracy: 0.5417\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6702 - categorical_accuracy: 0.5762 - val_loss: 0.6910 - val_categorical_accuracy: 0.5417\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6593 - categorical_accuracy: 0.5762 - val_loss: 0.6914 - val_categorical_accuracy: 0.5417\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6453 - categorical_accuracy: 0.5762 - val_loss: 0.6901 - val_categorical_accuracy: 0.5417\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6327 - categorical_accuracy: 0.5762 - val_loss: 0.6675 - val_categorical_accuracy: 0.5417\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6194 - categorical_accuracy: 0.5762 - val_loss: 0.6416 - val_categorical_accuracy: 0.5417\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6067 - categorical_accuracy: 0.5762 - val_loss: 0.6156 - val_categorical_accuracy: 0.5417\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5924 - categorical_accuracy: 0.5762 - val_loss: 0.5893 - val_categorical_accuracy: 0.5417\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5811 - categorical_accuracy: 0.57 - 0s 6ms/step - loss: 0.5806 - categorical_accuracy: 0.5762 - val_loss: 0.5698 - val_categorical_accuracy: 0.5417\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5637 - categorical_accuracy: 0.5762 - val_loss: 0.5784 - val_categorical_accuracy: 0.5417\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5471 - categorical_accuracy: 0.8139 - val_loss: 0.5199 - val_categorical_accuracy: 0.8854\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5283 - categorical_accuracy: 0.8197 - val_loss: 0.5147 - val_categorical_accuracy: 0.8385\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5234 - categorical_accuracy: 0.8151 - val_loss: 0.4871 - val_categorical_accuracy: 0.8698\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5059 - categorical_accuracy: 0.8325 - val_loss: 0.4783 - val_categorical_accuracy: 0.8646\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4959 - categorical_accuracy: 0.8301 - val_loss: 0.4752 - val_categorical_accuracy: 0.8385\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4853 - categorical_accuracy: 0.8365 - val_loss: 0.4634 - val_categorical_accuracy: 0.8385\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4835 - categorical_accuracy: 0.8249 - val_loss: 0.4767 - val_categorical_accuracy: 0.8490\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4691 - categorical_accuracy: 0.8330 - val_loss: 0.4974 - val_categorical_accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4645 - categorical_accuracy: 0.8359 - val_loss: 0.4599 - val_categorical_accuracy: 0.8594\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4547 - categorical_accuracy: 0.8330 - val_loss: 0.4545 - val_categorical_accuracy: 0.8542\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4619 - categorical_accuracy: 0.8301 - val_loss: 0.4378 - val_categorical_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4440 - categorical_accuracy: 0.8296 - val_loss: 0.4591 - val_categorical_accuracy: 0.8490\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4610 - categorical_accuracy: 0.8157 - val_loss: 0.3949 - val_categorical_accuracy: 0.9010\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4460 - categorical_accuracy: 0.8319 - val_loss: 0.4095 - val_categorical_accuracy: 0.8490\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4386 - categorical_accuracy: 0.8267 - val_loss: 0.4158 - val_categorical_accuracy: 0.8542\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4558 - categorical_accuracy: 0.8151 - val_loss: 0.4101 - val_categorical_accuracy: 0.8646\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4353 - categorical_accuracy: 0.8365 - val_loss: 0.3872 - val_categorical_accuracy: 0.8802\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4449 - categorical_accuracy: 0.8249 - val_loss: 0.4002 - val_categorical_accuracy: 0.8385\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4137 - categorical_accuracy: 0.8406 - val_loss: 0.3816 - val_categorical_accuracy: 0.8802\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4258 - categorical_accuracy: 0.8313 - val_loss: 0.3884 - val_categorical_accuracy: 0.8646\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4254 - categorical_accuracy: 0.8342 - val_loss: 0.3909 - val_categorical_accuracy: 0.8542\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4214 - categorical_accuracy: 0.8330 - val_loss: 0.3659 - val_categorical_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4119 - categorical_accuracy: 0.8394 - val_loss: 0.3818 - val_categorical_accuracy: 0.8646\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4153 - categorical_accuracy: 0.8278 - val_loss: 0.3952 - val_categorical_accuracy: 0.8594\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4077 - categorical_accuracy: 0.8371 - val_loss: 0.3615 - val_categorical_accuracy: 0.8802\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4036 - categorical_accuracy: 0.8365 - val_loss: 0.3633 - val_categorical_accuracy: 0.8802\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4046 - categorical_accuracy: 0.8417 - val_loss: 0.3693 - val_categorical_accuracy: 0.8958\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4069 - categorical_accuracy: 0.8336 - val_loss: 0.3957 - val_categorical_accuracy: 0.8438\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4130 - categorical_accuracy: 0.8290 - val_loss: 0.3871 - val_categorical_accuracy: 0.8385\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4107 - categorical_accuracy: 0.8359 - val_loss: 0.4018 - val_categorical_accuracy: 0.8229\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4096 - categorical_accuracy: 0.8243 - val_loss: 0.3936 - val_categorical_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3982 - categorical_accuracy: 0.8388 - val_loss: 0.3494 - val_categorical_accuracy: 0.8958\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4046 - categorical_accuracy: 0.8278 - val_loss: 0.3461 - val_categorical_accuracy: 0.8854\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3921 - categorical_accuracy: 0.8359 - val_loss: 0.3680 - val_categorical_accuracy: 0.8542\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3986 - categorical_accuracy: 0.8377 - val_loss: 0.3515 - val_categorical_accuracy: 0.8854\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4008 - categorical_accuracy: 0.8336 - val_loss: 0.3464 - val_categorical_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4084 - categorical_accuracy: 0.8209 - val_loss: 0.3612 - val_categorical_accuracy: 0.8385\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4102 - categorical_accuracy: 0.8342 - val_loss: 0.3386 - val_categorical_accuracy: 0.8802\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4054 - categorical_accuracy: 0.8278 - val_loss: 0.3432 - val_categorical_accuracy: 0.8802\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3956 - categorical_accuracy: 0.8423 - val_loss: 0.3601 - val_categorical_accuracy: 0.8385\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3873 - categorical_accuracy: 0.8441 - val_loss: 0.3323 - val_categorical_accuracy: 0.8906\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3949 - categorical_accuracy: 0.8325 - val_loss: 0.3341 - val_categorical_accuracy: 0.8854\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4018 - categorical_accuracy: 0.8272 - val_loss: 0.3659 - val_categorical_accuracy: 0.8281\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3891 - categorical_accuracy: 0.8423 - val_loss: 0.3358 - val_categorical_accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4023 - categorical_accuracy: 0.83 - 0s 6ms/step - loss: 0.3974 - categorical_accuracy: 0.8359 - val_loss: 0.3567 - val_categorical_accuracy: 0.8542\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3974 - categorical_accuracy: 0.8406 - val_loss: 0.3436 - val_categorical_accuracy: 0.8698\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4036 - categorical_accuracy: 0.8290 - val_loss: 0.3312 - val_categorical_accuracy: 0.8854\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3913 - categorical_accuracy: 0.8400 - val_loss: 0.3621 - val_categorical_accuracy: 0.8385\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3919 - categorical_accuracy: 0.8354 - val_loss: 0.3306 - val_categorical_accuracy: 0.8698\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3850 - categorical_accuracy: 0.8435 - val_loss: 0.3301 - val_categorical_accuracy: 0.8802\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3878 - categorical_accuracy: 0.8417 - val_loss: 0.3327 - val_categorical_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3989 - categorical_accuracy: 0.8354 - val_loss: 0.3252 - val_categorical_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3813 - categorical_accuracy: 0.8435 - val_loss: 0.3435 - val_categorical_accuracy: 0.8646\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3901 - categorical_accuracy: 0.8325 - val_loss: 0.3313 - val_categorical_accuracy: 0.8802\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3949 - categorical_accuracy: 0.8354 - val_loss: 0.3271 - val_categorical_accuracy: 0.8646\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4058 - categorical_accuracy: 0.8249 - val_loss: 0.3354 - val_categorical_accuracy: 0.8542\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4113 - categorical_accuracy: 0.8122 - val_loss: 0.3311 - val_categorical_accuracy: 0.8802\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3843 - categorical_accuracy: 0.8412 - val_loss: 0.3574 - val_categorical_accuracy: 0.8385\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3893 - categorical_accuracy: 0.8359 - val_loss: 0.3560 - val_categorical_accuracy: 0.8542\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4017 - categorical_accuracy: 0.8261 - val_loss: 0.3213 - val_categorical_accuracy: 0.8854\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3823 - categorical_accuracy: 0.8412 - val_loss: 0.3230 - val_categorical_accuracy: 0.8750\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3822 - categorical_accuracy: 0.8383 - val_loss: 0.3139 - val_categorical_accuracy: 0.8958\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3993 - categorical_accuracy: 0.8267 - val_loss: 0.3174 - val_categorical_accuracy: 0.8906\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3900 - categorical_accuracy: 0.8417 - val_loss: 0.3271 - val_categorical_accuracy: 0.8646\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3954 - categorical_accuracy: 0.8330 - val_loss: 0.3307 - val_categorical_accuracy: 0.8802\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3849 - categorical_accuracy: 0.8412 - val_loss: 0.4039 - val_categorical_accuracy: 0.8177\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3922 - categorical_accuracy: 0.8301 - val_loss: 0.3179 - val_categorical_accuracy: 0.9010\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3798 - categorical_accuracy: 0.8406 - val_loss: 0.3069 - val_categorical_accuracy: 0.8854\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3843 - categorical_accuracy: 0.8383 - val_loss: 0.3574 - val_categorical_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3969 - categorical_accuracy: 0.8261 - val_loss: 0.3277 - val_categorical_accuracy: 0.8542\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3804 - categorical_accuracy: 0.8336 - val_loss: 0.3459 - val_categorical_accuracy: 0.8438\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3823 - categorical_accuracy: 0.8394 - val_loss: 0.3162 - val_categorical_accuracy: 0.8646\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3858 - categorical_accuracy: 0.8394 - val_loss: 0.3100 - val_categorical_accuracy: 0.8854\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3825 - categorical_accuracy: 0.8429 - val_loss: 0.3665 - val_categorical_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3769 - categorical_accuracy: 0.8394 - val_loss: 0.3350 - val_categorical_accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3768 - categorical_accuracy: 0.8400 - val_loss: 0.3073 - val_categorical_accuracy: 0.8906\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3947 - categorical_accuracy: 0.8330 - val_loss: 0.3099 - val_categorical_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3791 - categorical_accuracy: 0.8377 - val_loss: 0.3145 - val_categorical_accuracy: 0.8854\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3814 - categorical_accuracy: 0.8388 - val_loss: 0.3133 - val_categorical_accuracy: 0.8854\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3708 - categorical_accuracy: 0.8475 - val_loss: 0.3326 - val_categorical_accuracy: 0.8802\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3831 - categorical_accuracy: 0.8354 - val_loss: 0.3376 - val_categorical_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3787 - categorical_accuracy: 0.8441 - val_loss: 0.3356 - val_categorical_accuracy: 0.8490\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3902 - categorical_accuracy: 0.8296 - val_loss: 0.3707 - val_categorical_accuracy: 0.8385\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3913 - categorical_accuracy: 0.8354 - val_loss: 0.3272 - val_categorical_accuracy: 0.8594\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3827 - categorical_accuracy: 0.8377 - val_loss: 0.3226 - val_categorical_accuracy: 0.8646\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4026 - categorical_accuracy: 0.8151 - val_loss: 0.3605 - val_categorical_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3888 - categorical_accuracy: 0.8383 - val_loss: 0.3276 - val_categorical_accuracy: 0.8646\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3850 - categorical_accuracy: 0.8336 - val_loss: 0.3418 - val_categorical_accuracy: 0.8333\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 1, 64)             18944     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 4         \n",
      "=================================================================\n",
      "Total params: 119,109\n",
      "Trainable params: 118,597\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 8s 30ms/step - loss: 0.7243 - categorical_accuracy: 0.5681 - val_loss: 0.6905 - val_categorical_accuracy: 0.6094\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6941 - categorical_accuracy: 0.5751 - val_loss: 0.6874 - val_categorical_accuracy: 0.6094\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6904 - categorical_accuracy: 0.5745 - val_loss: 0.6846 - val_categorical_accuracy: 0.6094\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6882 - categorical_accuracy: 0.5722 - val_loss: 0.6826 - val_categorical_accuracy: 0.6094\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6869 - categorical_accuracy: 0.5716 - val_loss: 0.6808 - val_categorical_accuracy: 0.6094\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.6859 - categorical_accuracy: 0.5716 - val_loss: 0.6793 - val_categorical_accuracy: 0.6094\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.6851 - categorical_accuracy: 0.5716 - val_loss: 0.6781 - val_categorical_accuracy: 0.6094\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6846 - categorical_accuracy: 0.5716 - val_loss: 0.6771 - val_categorical_accuracy: 0.6094\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.6842 - categorical_accuracy: 0.5716 - val_loss: 0.6763 - val_categorical_accuracy: 0.6094\n",
      "Epoch 10/100\n",
      "17/54 [========>.....................] - ETA: 0s - loss: 0.6817 - categorical_accuracy: 0.5827"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\20987\\Desktop\\dataset\\开心果数据集\\Pistachio_DeepLearning\\datasModels.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m filepath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m{categorical_accuracy:.4f}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{epoch:02d}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdropout_\u001b[39m\u001b[39m{\u001b[39;00mthe_dropout\u001b[39m}\u001b[39;00m\u001b[39m_batch_size_\u001b[39m\u001b[39m{\u001b[39;00mthe_batch_size\u001b[39m}\u001b[39;00m\u001b[39m_optimizer_\u001b[39m\u001b[39m{\u001b[39;00mthe_optimizer\u001b[39m}\u001b[39;00m\u001b[39m_dense_layers_\u001b[39m\u001b[39m{\u001b[39;00mthe_dense_layers\u001b[39m}\u001b[39;00m\u001b[39m_lstm_layers_\u001b[39m\u001b[39m{\u001b[39;00mthe_lstm_layers\u001b[39m}\u001b[39;00m\u001b[39m_unit_\u001b[39m\u001b[39m{\u001b[39;00mthe_units\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                     filepath\u001b[39m=\u001b[39mfilepath,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m                     save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m                     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m                     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m                     \u001b[39m#callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/datasModels.ipynb#X11sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcheckpoint)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#定义模型\n",
    "\n",
    "sgd = SGD(learning_rate=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lstm_layers = [1,2,3,4,5]\n",
    "dense_layers = [1,2,3,4,5,6]\n",
    "units = [16,32,64,128]\n",
    "dropout = [0.05,0.1,0.15,0.25]\n",
    "Batch_size = [32,64,128]\n",
    "optimizer = ['adam',sgd]\n",
    "for the_batch_size in Batch_size:\n",
    "    for the_dropout in dropout:\n",
    "        for the_optimizer in optimizer:\n",
    "            for the_dense_layers in dense_layers:\n",
    "                for the_lstm_layers in lstm_layers:\n",
    "                    for the_units in units:\n",
    "                        sgd = SGD(learning_rate=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "                        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=random.randint(10,100))\n",
    "                        X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "                        X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "                        model = Sequential()\n",
    "                        # model.build(input_shape=(277,277,2))\n",
    "                        #print(model.summary())\n",
    "                        #model.add(SpatialDropout1D(0.2))\n",
    "                        model.add(LSTM(the_units ,input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences = True))\n",
    "                        model.add(Dropout(the_dropout))\n",
    "                        model.add(BatchNormalization())\n",
    "                        # #第二层\n",
    "                        for i in range(the_lstm_layers):\n",
    "                            model.add(LSTM(the_units,return_sequences=True))\n",
    "                            model.add(Dropout(the_dropout))\n",
    "                            model.add(BatchNormalization())\n",
    "\n",
    "                        model.add(LSTM(the_units))\n",
    "                        model.add(Dropout(the_dropout))\n",
    "                        model.add(BatchNormalization())\n",
    "                        #全连接层\n",
    "                        for i in range(the_dense_layers):\n",
    "                            model.add(Dense(the_dense_layers,activation='relu'))\n",
    "                            model.add(Dropout(the_dropout))\n",
    "                            \n",
    "                        # model.add(Flatten()) \n",
    "                        \n",
    "                        \n",
    "                        model.add(Dense(2, activation='softmax'))\n",
    "                        \n",
    "                        #sgd = SGD(learning_rate=0.01, momentum=0.9 , decay=0.1, nesterov=False)\n",
    "                        \n",
    "                        # learning_rate = 0.1\n",
    "                        # decay = 0.001\n",
    "                        # epochs = 50\n",
    "                        # batch_size = 64\n",
    "                        \n",
    "                        \n",
    "                        model.compile(  loss='binary_crossentropy',#categorical_crossentropy', binary_crossentropy\n",
    "                                        optimizer=the_optimizer, metrics=['categorical_accuracy'])\n",
    "                        print(model.summary())\n",
    "\n",
    "                        epochs = 100\n",
    "                        batch_size = the_batch_size\n",
    "                        if(the_optimizer == sgd):\n",
    "                            the_optimizer = 'sgd'\n",
    "                        filepath = './models/{categorical_accuracy:.4f}_{epoch:02d}_'+f'dropout_{the_dropout}_batch_size_{the_batch_size}_optimizer_{the_optimizer}_dense_layers_{the_dense_layers}_lstm_layers_{the_lstm_layers}_unit_{the_units}.h5'\n",
    "                        checkpoint = ModelCheckpoint(\n",
    "                                            filepath=filepath,\n",
    "                                            save_weights_only=False,\n",
    "                                            monitor='categorical_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True)\n",
    "                        history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1,\n",
    "                                            #callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "                                            callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model('./models/0.8597_99_dropout_0.05_batch_size_32_optimizer_adam_dense_layers_1_lstm_layers_1_unit_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.7074190e-05 9.9992287e-01]\n",
      " [9.5783162e-01 4.2168371e-02]\n",
      " [8.8447960e-05 9.9991155e-01]\n",
      " [9.5783162e-01 4.2168371e-02]\n",
      " [9.5783162e-01 4.2168371e-02]\n",
      " [9.5783162e-01 4.2168371e-02]\n",
      " [3.7874389e-04 9.9962127e-01]\n",
      " [6.3452451e-04 9.9936551e-01]\n",
      " [1.2191693e-04 9.9987805e-01]\n",
      " [8.4994914e-04 9.9915004e-01]\n",
      " [2.3041708e-04 9.9976963e-01]\n",
      " [9.5783162e-01 4.2168371e-02]\n",
      " [9.5783162e-01 4.2168371e-02]\n",
      " [3.0745062e-01 6.9254935e-01]\n",
      " [1.3609251e-01 8.6390746e-01]\n",
      " [6.9754067e-05 9.9993026e-01]\n",
      " [2.5877409e-04 9.9974126e-01]]\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "ACC: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('test.csv') \n",
    "cols = ['Class','Area', 'Perimeter', 'Major_Axis', 'Minor_Axis', 'Eccentricity',\n",
    "        'Eqdiasq', 'Solidity', 'Convex_Area', 'Extent', 'Aspect_Ratio',\n",
    "        'Roundness', 'Compactness', 'Shapefactor_1', 'Shapefactor_2',\n",
    "        'Shapefactor_3', 'Shapefactor_4', 'Mean_RR', 'Mean_RG', 'Mean_RB',\n",
    "        'StdDev_RR', 'StdDev_RG', 'StdDev_RB', 'Skew_RR', 'Skew_RG', 'Skew_RB',\n",
    "        'Kurtosis_RR', 'Kurtosis_RG', 'Kurtosis_RB']\n",
    "\n",
    "lis = []\n",
    "for i in range(28):\n",
    "    lis.append(27-i)\n",
    "\n",
    "Lisclass = dataset['Class'].values\n",
    "LisClassNp = []\n",
    "for i in range(len(Lisclass)):\n",
    "    if (Lisclass[i] == 'Kirmizi_Pistachio'):\n",
    "        LisClassNp.append([0,1])\n",
    "    else:\n",
    "        LisClassNp.append([1,0])\n",
    "Y = np.array(LisClassNp)\n",
    "dataset = dataset.drop(columns='Class')\n",
    "# lisindex = []\n",
    "# for i in range(len(dataset.columns)):\n",
    "#     lisindex.append(i)\n",
    "# dataset = dataset.reindex(lisindex)\n",
    "colIndex = ['Area','Minor_Axis', 'Eccentricity',\n",
    "            'Eqdiasq','Convex_Area', 'Aspect_Ratio',\n",
    "            'Compactness', 'Shapefactor_1', \n",
    "            'Shapefactor_3']\n",
    "#colIndex = FReIndex(colIndex,lis)\n",
    "dataset = pd.DataFrame(dataset,columns=colIndex)\n",
    "\n",
    "X = dataset.values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "#进行预测 make a prediction\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.9, random_state=random.randint(10,100))\n",
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "# print ('train_x.shape, train_y.shape, test_x.shape, test_y.shape')\n",
    "# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "yhat = best_model.predict(X_test)\n",
    "# print(yhat.shape)\n",
    "print(yhat)\n",
    "print(Y_test)\n",
    "sorce = 0\n",
    "for i in range(len(Y_test)):\n",
    "    sorce += roc_auc_score(Y_test[i], yhat[i])\n",
    "\n",
    "print('ACC:',sorce/len(Y_test))\n",
    "#拆分训练集和测试集\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=random.randint(10,100))\n",
    "# X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "# X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33d73dfb9d58d1e4c0ed15f266f7c1fd1b5e79268076ebae9c660cb33abbd60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
