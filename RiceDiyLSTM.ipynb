{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from random import shuffle\n",
    "from DiyLSTMmod import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('./dataset/Rice_MSC_Dataset.xlsx','Rice_MSC_Dataset')\n",
    "df = pd.read_excel('./dataset/Rice_MSC_Dataset.xlsx')\n",
    "#df = shuffle(df)\n",
    "# df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>ALLdaub4L</th>\n",
       "      <th>ALLdaub4a</th>\n",
       "      <th>ALLdaub4b</th>\n",
       "      <th>ALLdaub4Y</th>\n",
       "      <th>ALLdaub4Cb</th>\n",
       "      <th>ALLdaub4Cr</th>\n",
       "      <th>ALLdaub4XX</th>\n",
       "      <th>ALLdaub4YY</th>\n",
       "      <th>ALLdaub4ZZ</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7805</td>\n",
       "      <td>437.915</td>\n",
       "      <td>209.8215</td>\n",
       "      <td>48.0221</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>99.6877</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>7985</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>4.3693</td>\n",
       "      <td>...</td>\n",
       "      <td>113.9924</td>\n",
       "      <td>65.0610</td>\n",
       "      <td>59.5989</td>\n",
       "      <td>104.8552</td>\n",
       "      <td>67.8779</td>\n",
       "      <td>63.0828</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7503</td>\n",
       "      <td>340.757</td>\n",
       "      <td>138.3361</td>\n",
       "      <td>69.8417</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>97.7400</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>7767</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>...</td>\n",
       "      <td>105.7055</td>\n",
       "      <td>64.3685</td>\n",
       "      <td>62.2084</td>\n",
       "      <td>96.8375</td>\n",
       "      <td>65.5371</td>\n",
       "      <td>63.5832</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>0.3641</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5124</td>\n",
       "      <td>314.617</td>\n",
       "      <td>141.9803</td>\n",
       "      <td>46.5784</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>80.7718</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5271</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>3.0482</td>\n",
       "      <td>...</td>\n",
       "      <td>109.7155</td>\n",
       "      <td>62.6423</td>\n",
       "      <td>58.7439</td>\n",
       "      <td>100.2352</td>\n",
       "      <td>68.9753</td>\n",
       "      <td>59.8342</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>0.4448</td>\n",
       "      <td>Jasmine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7990</td>\n",
       "      <td>437.085</td>\n",
       "      <td>201.4386</td>\n",
       "      <td>51.2245</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>100.8622</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>8272</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>3.9325</td>\n",
       "      <td>...</td>\n",
       "      <td>116.5405</td>\n",
       "      <td>64.9069</td>\n",
       "      <td>60.2562</td>\n",
       "      <td>107.2560</td>\n",
       "      <td>67.3298</td>\n",
       "      <td>63.2237</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>Basmati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7433</td>\n",
       "      <td>342.893</td>\n",
       "      <td>140.3350</td>\n",
       "      <td>68.3927</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>97.2830</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>7561</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>2.0519</td>\n",
       "      <td>...</td>\n",
       "      <td>107.7502</td>\n",
       "      <td>64.7071</td>\n",
       "      <td>61.3549</td>\n",
       "      <td>98.8704</td>\n",
       "      <td>66.2048</td>\n",
       "      <td>63.5378</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>Arborio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  SOLIDITY  \\\n",
       "0  7805    437.915    209.8215     48.0221        0.9735   99.6877    0.9775   \n",
       "1  7503    340.757    138.3361     69.8417        0.8632   97.7400    0.9660   \n",
       "2  5124    314.617    141.9803     46.5784        0.9447   80.7718    0.9721   \n",
       "3  7990    437.085    201.4386     51.2245        0.9671  100.8622    0.9659   \n",
       "4  7433    342.893    140.3350     68.3927        0.8732   97.2830    0.9831   \n",
       "\n",
       "   CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  ALLdaub4L  ALLdaub4a  ALLdaub4b  \\\n",
       "0         7985  0.3547        4.3693  ...   113.9924    65.0610    59.5989   \n",
       "1         7767  0.6637        1.9807  ...   105.7055    64.3685    62.2084   \n",
       "2         5271  0.4760        3.0482  ...   109.7155    62.6423    58.7439   \n",
       "3         8272  0.6274        3.9325  ...   116.5405    64.9069    60.2562   \n",
       "4         7561  0.6006        2.0519  ...   107.7502    64.7071    61.3549   \n",
       "\n",
       "   ALLdaub4Y  ALLdaub4Cb  ALLdaub4Cr  ALLdaub4XX  ALLdaub4YY  ALLdaub4ZZ  \\\n",
       "0   104.8552     67.8779     63.0828      0.3673      0.3793      0.4733   \n",
       "1    96.8375     65.5371     63.5832      0.3014      0.3144      0.3641   \n",
       "2   100.2352     68.9753     59.8342      0.3233      0.3445      0.4448   \n",
       "3   107.2560     67.3298     63.2237      0.3880      0.4020      0.4904   \n",
       "4    98.8704     66.2048     63.5378      0.3184      0.3303      0.3928   \n",
       "\n",
       "     CLASS  \n",
       "0  Basmati  \n",
       "1  Arborio  \n",
       "2  Jasmine  \n",
       "3  Basmati  \n",
       "4  Arborio  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'AREA,'PERIMETER','MAJOR_AXIS','MINOR_AXIS,'ECCENTRICITY','EQDIASQ','SOLIDITY','CONVEX_AREA','EXTENT','ASPECT_RATIO','ROUNDNESS','COMPACTNESS','SHAPEFACTOR_1','SHAPEFACTOR_2','SHAPEFACTOR_3' ,'SHAPEFACTOR_4','meanRR,'meanRG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['AREA','PERIMETER','MAJOR_AXIS','MINOR_AXIS','ECCENTRICITY','EQDIASQ','SOLIDITY','CONVEX_AREA','EXTENT','ASPECT_RATIO','ROUNDNESS','COMPACTNESS','SHAPEFACTOR_1','SHAPEFACTOR_2','SHAPEFACTOR_3' ,'SHAPEFACTOR_4','meanRR','meanRG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lis =['Basmati', 'Arborio', 'Jasmine', 'Ipsala', 'Karacadag']\n",
    "df_class = pd.DataFrame()\n",
    "df_class['Class']=df['CLASS'].map(\n",
    "{\n",
    "    'Basmati':0,\n",
    "    'Arborio':1, \n",
    "    'Jasmine':2, \n",
    "    'Ipsala':3,\n",
    "    'Karacadag':4\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class\n",
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          0\n",
       "4          1\n",
       "...      ...\n",
       "74995      1\n",
       "74996      4\n",
       "74997      1\n",
       "74998      3\n",
       "74999      3\n",
       "\n",
       "[75000 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LisClassNp = df_class['Class'].values\n",
    "Y = np.array(LisClassNp)\n",
    "df = df.drop(columns='CLASS')\n",
    "X = df.values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拆分训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.001, random_state=40)\n",
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "#X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "\n",
    "X_train = tf.cast(X_train, dtype='float32')\n",
    "#X_test = tf.cast(X_test, dtype='float32')\n",
    "Y_train = tf.cast(Y_train, dtype='float32')\n",
    "# Y_test = tf.cast(Y_test, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([74925, 1, 106])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [128,106], In[1]: [7,128] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\20987\\Desktop\\Pistachio_DeepLearning\\RiceDiyLSTM.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/RiceDiyLSTM.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m valid_acc \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/RiceDiyLSTM.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/RiceDiyLSTM.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     t,v \u001b[39m=\u001b[39m k_fold(\u001b[39m10\u001b[39;49m, X_train, Y_train,\u001b[39m100\u001b[39;49m,\u001b[39m128\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/RiceDiyLSTM.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_acc\u001b[39m.\u001b[39mappend(t)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/RiceDiyLSTM.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     valid_acc\u001b[39m.\u001b[39mappend(v)\n",
      "File \u001b[1;32mc:\\Users\\20987\\Desktop\\Pistachio_DeepLearning\\DiyLSTMmod.py:208\u001b[0m, in \u001b[0;36mk_fold\u001b[1;34m(k, X_train, y_train, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m    200\u001b[0m cp_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(filepath\u001b[39m=\u001b[39mcheckpoint_path,\n\u001b[0;32m    201\u001b[0m                                         save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    202\u001b[0m                                         monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    203\u001b[0m                                         mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    204\u001b[0m                                         verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    205\u001b[0m                                         save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    206\u001b[0m net\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m#categorical_crossentropy', binary_crossentropy\u001b[39;00m\n\u001b[0;32m    207\u001b[0m         optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m'\u001b[39m],run_eagerly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \n\u001b[1;32m--> 208\u001b[0m history \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mfit(X_train2, y_train2,batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    209\u001b[0m                                 epochs\u001b[39m=\u001b[39;49mnum_epochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_valid, y_valid), validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, \n\u001b[0;32m    210\u001b[0m                                 validation_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49mcp_callback)\n\u001b[0;32m    211\u001b[0m train_ls \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    212\u001b[0m valid_ls \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_categorical_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:66\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_method_wrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     68\u001b[0m   \u001b[39m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m   \u001b[39mif\u001b[39;00m dc_context\u001b[39m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:848\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mwith\u001b[39;00m traceme\u001b[39m.\u001b[39mTraceMe(\n\u001b[0;32m    842\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTraceContext\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    843\u001b[0m     graph_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    844\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m    845\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m    846\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m    847\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 848\u001b[0m   tmp_logs \u001b[39m=\u001b[39m train_function(iterator)\n\u001b[0;32m    849\u001b[0m   \u001b[39m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m   \u001b[39m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[0;32m    851\u001b[0m   \u001b[39m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[0;32m    852\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_handler\u001b[39m.\u001b[39minferred_steps:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m    570\u001b[0m   data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 571\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    572\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m    573\u001b[0m   outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    574\u001b[0m       outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    575\u001b[0m   \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m    947\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m    948\u001b[0m   \u001b[39m# applied when when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m    949\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    950\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 951\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2288\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2289\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2290\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   2646\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\n\u001b[0;32m   2647\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(),\n\u001b[0;32m   2648\u001b[0m       replica_id_in_sync_group\u001b[39m=\u001b[39mconstant_op\u001b[39m.\u001b[39mconstant(\u001b[39m0\u001b[39m, dtypes\u001b[39m.\u001b[39mint32)):\n\u001b[1;32m-> 2649\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:282\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    281\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:531\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    528\u001b[0m x, y, sample_weight \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[0;32m    530\u001b[0m \u001b[39mwith\u001b[39;00m backprop\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 531\u001b[0m   y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    532\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(\n\u001b[0;32m    533\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n\u001b[0;32m    534\u001b[0m \u001b[39m# For custom training steps, users can just write:\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39m#   trainable_variables = self.trainable_variables\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[39m#   gradients = tape.gradient(loss, trainable_variables)\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[39m#   self.optimizer.apply_gradients(zip(gradients, trainable_variables))\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[39m# The _minimize call does a few extra steps unnecessary in most cases,\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39m# such as loss scaling and gradient clipping.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:968\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    965\u001b[0m cast_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m    966\u001b[0m \u001b[39mwith\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mautocast_context_manager(\n\u001b[0;32m    967\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype):\n\u001b[1;32m--> 968\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks)\n",
      "File \u001b[1;32mc:\\Users\\20987\\Desktop\\Pistachio_DeepLearning\\DiyLSTMmod.py:136\u001b[0m, in \u001b[0;36mmy_model.call\u001b[1;34m(self, inputdata, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    127\u001b[0m             \n\u001b[0;32m    128\u001b[0m     \u001b[39m##x1 = self.LSTM0(inputdata)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[39m#c = self.DROP(x1)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[39m##c = self.BAT(x1)\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLSTM1(inputdata)\n\u001b[0;32m    137\u001b[0m     \u001b[39m#print(hasattr(c, '_keras_history'))\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDROP(c)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:968\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    965\u001b[0m cast_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m    966\u001b[0m \u001b[39mwith\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mautocast_context_manager(\n\u001b[0;32m    967\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype):\n\u001b[1;32m--> 968\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks)\n",
      "File \u001b[1;32mc:\\Users\\20987\\Desktop\\Pistachio_DeepLearning\\DiyLSTMmod.py:65\u001b[0m, in \u001b[0;36mCustomLSTM.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m xt \u001b[39m=\u001b[39m x[:, \u001b[39m0\u001b[39m ,:]\n\u001b[0;32m     62\u001b[0m \u001b[39m#ft = tf.sigmoid(tf.matmul(xt,self.wf) + self.bf)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m# it = tf.sigmoid(tf.matmul(xt,self.wi) + self.bi)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m# ot = tf.sigmoid(tf.matmul(xt,self.wo) + self.bo)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m it \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msigmoid(tf\u001b[39m.\u001b[39;49mmatmul(xt,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwi) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbi)\n\u001b[0;32m     66\u001b[0m ot \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msigmoid(tf\u001b[39m.\u001b[39mmatmul(xt,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwo) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbo)\n\u001b[0;32m     67\u001b[0m cht \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtanh(tf\u001b[39m.\u001b[39mmatmul(xt,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwc) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:180\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    181\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    182\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    183\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2983\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2981\u001b[0m   \u001b[39mreturn\u001b[39;00m ret\n\u001b[0;32m   2982\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2983\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[0;32m   2984\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:5577\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5575\u001b[0m       \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   5576\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 5577\u001b[0m     _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   5578\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   5579\u001b[0m \u001b[39mif\u001b[39;00m transpose_a \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:6653\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6651\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6652\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6653\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [128,106], In[1]: [7,128] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./models_RICE/cp-{categorical_accuracy:.5f}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "for i in range(10):\n",
    "    t,v = k_fold(10, X_train, Y_train,100,128)\n",
    "    train_acc.append(t)\n",
    "    valid_acc.append(v)\n",
    "print('训练集：',train_acc)\n",
    "print('验证集:',valid_acc)\n",
    "\n",
    "print('训练集平均，验证集平均：',ave_list(train_acc),ave_list(valid_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33d73dfb9d58d1e4c0ed15f266f7c1fd1b5e79268076ebae9c660cb33abbd60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
