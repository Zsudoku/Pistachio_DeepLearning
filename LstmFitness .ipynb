{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# coding=utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.core import Flatten\n",
    "import random,os,sys,shutil\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout,LSTM,BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "from optimizationAlgorithm import *\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FReIndex(colIndex,reIndex):\n",
    "    dirindex = {}\n",
    "    lisindex = []\n",
    "    for i in range(len(colIndex)):\n",
    "        lisindex.append(i)\n",
    "    dirindex = dict(zip(lisindex,colIndex))\n",
    "    colIndex = []\n",
    "    for i in range(len(reIndex)):\n",
    "        for key in dirindex:\n",
    "            if int(key) + 1 == int(reIndex[i]):\n",
    "                colIndex.append(dirindex[key])\n",
    "                break\n",
    "    #print(colIndex)\n",
    "    return colIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_dataset_X_Y(lis,data_path):\n",
    "    dataset = pd.read_csv(data_path) \n",
    "    dataset = shuffle(dataset)\n",
    "    Lisclass = dataset['Class'].values\n",
    "    LisClassNp = []\n",
    "    for i in range(len(Lisclass)):\n",
    "        if (Lisclass[i] == 'Kirmizi_Pistachio'):\n",
    "            LisClassNp.append([0,1])\n",
    "        else:\n",
    "            LisClassNp.append([1,0])\n",
    "    Y = np.array(LisClassNp)\n",
    "    dataset = dataset.drop(columns='Class')\n",
    "\n",
    "    colIndex = ['Area','Minor_Axis', 'Eccentricity',\n",
    "                'Eqdiasq','Convex_Area', 'Aspect_Ratio',\n",
    "                'Compactness', 'Shapefactor_1', \n",
    "                'Shapefactor_3']\n",
    "\n",
    "    # lis = [] #优化算法参数入口（编码）\n",
    "    # for i in range(len(colIndex)):\n",
    "    #     lis.append(len(colIndex)-i)\n",
    "        \n",
    "    colIndex = FReIndex(colIndex,lis)\n",
    "    dataset = pd.DataFrame(dataset,columns=colIndex)\n",
    "    X = dataset.values\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "def train_models(X,Y,lis):\n",
    "    \n",
    "    sgd = SGD(learning_rate=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    lstm_layers = [3]\n",
    "    dense_layers = [3]\n",
    "    units = [32]\n",
    "    dropout = [0.05]\n",
    "    Batch_size = [64]\n",
    "    optimizer = [sgd]\n",
    "    for the_batch_size in Batch_size:\n",
    "        for the_dropout in dropout:\n",
    "            for the_optimizer in optimizer:\n",
    "                for the_dense_layers in dense_layers:\n",
    "                    for the_lstm_layers in lstm_layers:\n",
    "                        for the_units in units:\n",
    "                            sgd = SGD(learning_rate=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "                            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=random.randint(10,100))\n",
    "                            X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "                            X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "                            model = Sequential()\n",
    "                            # model.build(input_shape=(277,277,2))\n",
    "                            #print(model.summary())\n",
    "                            #model.add(SpatialDropout1D(0.2))\n",
    "                            model.add(LSTM(the_units ,input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences = True))\n",
    "                            model.add(Dropout(the_dropout))\n",
    "                            model.add(BatchNormalization())\n",
    "                            # #第二层\n",
    "                            for i in range(the_lstm_layers):\n",
    "                                model.add(LSTM(the_units,return_sequences=True))\n",
    "                                model.add(Dropout(the_dropout))\n",
    "                                model.add(BatchNormalization())\n",
    "\n",
    "                            model.add(LSTM(the_units))\n",
    "                            model.add(Dropout(the_dropout))\n",
    "                            model.add(BatchNormalization())\n",
    "                            #全连接层\n",
    "                            for i in range(the_dense_layers):\n",
    "                                model.add(Dense(the_dense_layers,activation='relu'))\n",
    "                                model.add(Dropout(the_dropout))\n",
    "                                \n",
    "                            # model.add(Flatten()) \n",
    "                            \n",
    "                            \n",
    "                            model.add(Dense(2, activation='softmax'))\n",
    "                            \n",
    "                            #sgd = SGD(learning_rate=0.01, momentum=0.9 , decay=0.1, nesterov=False)\n",
    "                            \n",
    "                            # learning_rate = 0.1\n",
    "                            # decay = 0.001\n",
    "                            # epochs = 50\n",
    "                            # batch_size = 64\n",
    "                            \n",
    "                            \n",
    "                            model.compile(  loss='binary_crossentropy',#categorical_crossentropy', binary_crossentropy\n",
    "                                            optimizer=the_optimizer, metrics=['categorical_accuracy'])\n",
    "                            #print(model.summary())\n",
    "                            \n",
    "                            # if os.path.exists('models'):                         #判断是否存在输入的文件夹，存在则继续\n",
    "                            #     if os.path.exists('models/' + str(lis)):    \n",
    "                            #         pass#判断否存在输入的子文件夹\n",
    "                            #         #print('两个文件都已经存在')\n",
    "                            #     else:                                                                   # 文件夹存在，子文件夹不存在，则创建\n",
    "                            #         os.mkdir('models/' + str(lis))                                              #创建子文件夹\n",
    "                            #         #print('{}文件夹创建成功'.format('models/' + str(lis)))                       #打印XX文件夹创建成功\n",
    "                            # else:                                                                #文件夹不存在，则创建文件夹和子文件夹\n",
    "                            #     os.mkdir('models')                                                #创建文件夹\n",
    "                            #     os.mkdir('models/' + str(lis))                                                  #创建子文件夹\n",
    "                            #     #print('{}文件夹和{}文件夹创建成功'.format(desk_file_name,zi_file_name))\n",
    "                                \n",
    "                                \n",
    "                            epochs = 100\n",
    "                            batch_size = the_batch_size\n",
    "                            if(the_optimizer == sgd):\n",
    "                                the_optimizer = 'sgd'\n",
    "                            filename = str(lis)\n",
    "                            filepath = 'models/' + filename + '/{categorical_accuracy:.4f}.h5'\n",
    "                            checkpoint = ModelCheckpoint(\n",
    "                                                filepath=filepath,\n",
    "                                                save_weights_only=False,\n",
    "                                                monitor='categorical_accuracy',\n",
    "                                                mode='max',\n",
    "                                                save_best_only=True)\n",
    "                            history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1,\n",
    "                                                #callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "                                                verbose=0,callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_acc(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        pass\n",
    "    name = files[-1]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(max_acc('models')))\n",
    "# './Pistachio_Dataset/Pistachio_28_Features_Dataset/Pistachio_28_Features_Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_source(lis,filepath):\n",
    "    \n",
    "    best_model = load_model(filepath)\n",
    "    X,Y = creat_dataset_X_Y(lis,'test.csv')\n",
    "\n",
    "    #进行预测 make a prediction\n",
    "    X = X.reshape(X.shape[0],1,X.shape[1])\n",
    "    yhat = best_model.predict(X)\n",
    "\n",
    "    # print(yhat)\n",
    "    # print(Y)\n",
    "    sorce = 0\n",
    "    for i in range(len(Y)):\n",
    "        sorce += roc_auc_score(Y[i], yhat[i])\n",
    "\n",
    "    print('ACC:',sorce/len(Y))\n",
    "    return -sorce/len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enSimpleCode(lis):\n",
    "    X,Y = creat_dataset_X_Y(lis,'./Pistachio_Dataset/Pistachio_28_Features_Dataset/Pistachio_28_Features_Dataset.csv')\n",
    "    train_models(X,Y,lis)\n",
    "    path = 'models/' + str(lis)  + '/' + max_acc('models/' + str(lis))\n",
    "    return round(acc_source(lis,path),4) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('models')  \n",
    "os.mkdir('models')\n",
    "ColIndex = ['Area','Minor_Axis', 'Eccentricity',\n",
    "                'Eqdiasq','Convex_Area', 'Aspect_Ratio',\n",
    "                'Compactness', 'Shapefactor_1', \n",
    "                'Shapefactor_3']\n",
    "optAlgo = OptimizationAlgorithm(ColIndex)\n",
    "optAlgo.ga(enSimpleCode, len(ColIndex), 100, 2)\n",
    "\n",
    "#[9, 5, 1, 2, 6, 3, 4, 7, 8]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33d73dfb9d58d1e4c0ed15f266f7c1fd1b5e79268076ebae9c660cb33abbd60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
