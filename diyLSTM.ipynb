{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# coding=utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout,LSTM,BatchNormalization,Conv1D,MaxPool1D,Reshape,Input,Conv2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import torch\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import math \n",
    "import os\n",
    "import scipy.io as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./Pistachio_Dataset/Pistachio_28_Features_Dataset/Pistachio_28_Features_Dataset.csv') \n",
    "cols = ['Class','Area', 'Perimeter', 'Major_Axis', 'Minor_Axis', 'Eccentricity',\n",
    "        'Eqdiasq', 'Solidity', 'Convex_Area', 'Extent', 'Aspect_Ratio',\n",
    "        'Roundness', 'Compactness', 'Shapefactor_1', 'Shapefactor_2',\n",
    "        'Shapefactor_3', 'Shapefactor_4', 'Mean_RR', 'Mean_RG', 'Mean_RB',\n",
    "        'StdDev_RR', 'StdDev_RG', 'StdDev_RB', 'Skew_RR', 'Skew_RG', 'Skew_RB',\n",
    "        'Kurtosis_RR', 'Kurtosis_RG', 'Kurtosis_RB']\n",
    "dataset = shuffle(dataset)\n",
    "Lisclass = dataset['Class'].values\n",
    "LisClassNp = []\n",
    "for i in range(len(Lisclass)):\n",
    "    if (Lisclass[i] == 'Kirmizi_Pistachio'):\n",
    "        LisClassNp.append([0,1])\n",
    "    else:\n",
    "        LisClassNp.append([1,0])\n",
    "Y = np.array(LisClassNp)\n",
    "dataset = dataset.drop(columns='Class')\n",
    "X = dataset.values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "#拆分训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=40)\n",
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "\n",
    "X_train = tf.cast(X_train, dtype='float32')\n",
    "X_test = tf.cast(X_test, dtype='float32')\n",
    "Y_train = tf.cast(Y_train, dtype='float32')\n",
    "Y_test = tf.cast(Y_test, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "sequence_lenth = 1 #每个句子的长度\n",
    "input_size = 28    #每个时序的单独向量，代表每个字的含义\n",
    "output_size = 128\n",
    "x = X_train\n",
    "#x = tf.random.uniform((batch_size,sequence_lenth,input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM'S INOPUT: [batch_size,sequence_length,output_size]\n",
    "#LSTM'S OUTPUT1: [batch_size,sequence_length,output_size]\n",
    "#       OUTPUT2:[batch_size,output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    #LSTM'S INOPUT: [batch_size,sequence_length,output_size]\n",
    "    #LSTM'S OUTPUT1: [batch_size,sequence_length,output_size]\n",
    "    #       OUTPUT2:[batch_size,output_size]\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,output_size,return_sequences=False):\n",
    "        super(CustomLSTM,self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.return_sequences = return_sequences\n",
    "    def build(self,input_shape):\n",
    "        super(CustomLSTM,self).build(input_shape)\n",
    "        input_size = int(input_shape[-1])\n",
    "        #self.wf = self.add_weight('wf', shape=(input_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "        self.wi = self.add_weight('wi', shape=(input_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "        self.wo = self.add_weight('wo', shape=(input_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "        self.wc = self.add_weight('wc', shape=(input_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "\n",
    "        #self.uf = self.add_weight('uf', shape=(self.output_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "        #self.ui = self.add_weight('ui', shape=(self.output_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "        #self.uo = self.add_weight('uo', shape=(self.output_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "        #self.uc = self.add_weight('uc', shape=(self.output_size,self.output_size),initializer='random_normal',trainable=True)\n",
    "\n",
    "        #self.bf = self.add_weight('bf', shape=(1,self.output_size),initializer='random_normal',trainable=True)\n",
    "        self.bi = self.add_weight('bi', shape=(1,self.output_size),initializer='random_normal',trainable=True)\n",
    "        self.bo = self.add_weight('bo', shape=(1,self.output_size),initializer='random_normal',trainable=True)\n",
    "        self.bc = self.add_weight('bc', shape=(1,self.output_size),initializer='random_normal',trainable=True)\n",
    "    def call(self, x):\n",
    "        Para = []\n",
    "        sequence_outputs = []\n",
    "        for i in range(sequence_lenth):\n",
    "            if i == 0:\n",
    "                xt = x[:, 0 ,:]\n",
    "                it = tf.sigmoid(tf.matmul(xt,self.wi) + self.bi)\n",
    "                ot = tf.sigmoid(tf.matmul(xt,self.wo) + self.bo)\n",
    "                cht = tf.tanh(tf.matmul(xt,self.wc) + self.bc)\n",
    "                ct = it * cht\n",
    "                ht = ot * tf.tanh(ct)\n",
    "                # para1 = para1.numpy()\n",
    "                # para2 = para2.numpy()\n",
    "                # para3 = para3.numpy()\n",
    "                # para4 = para4.numpy()\n",
    "                # ct = ct.numpy()\n",
    "                # print(para1)\n",
    "                # np.savetxt('para1.txt',para1)\n",
    "                # np.savetxt('para2.txt',para2)\n",
    "                # np.savetxt('para3.txt',para3)\n",
    "                # np.savetxt('para4.txt',para4)\n",
    "                # np.savetxt('ct.txt',ct)\n",
    "                #io.savemat('save.mat',{'result1':result1})\n",
    "            else:\n",
    "                print('$$$$$$$$$$$$$$$$$$$$','this is else')\n",
    "                # xt = x[:, i ,:]\n",
    "                # para1 = tf.matmul(xt,self.wf) + tf.matmul(ht,self.uf) + self.bf\n",
    "                # para2 = tf.matmul(xt,self.wi) + tf.matmul(ht,self.ui) + self.bi\n",
    "                # para3 = tf.matmul(xt,self.wo) + tf.matmul(ht,self.uo) + self.bo\n",
    "                # para4 = tf.matmul(xt,self.wc) + tf.matmul(ht,self.uc) + self.bc\n",
    "                # ft = tf.sigmoid(para1)\n",
    "                # it = tf.sigmoid(para2)\n",
    "                # ot = tf.sigmoid(para3)\n",
    "                # cht = tf.tanh(para4)\n",
    "                # ct = ft * ct + it * cht\n",
    "                # ht = ot * tf.tanh(ct)\n",
    "                #Para.append([para1,para2,para3,para4,ct])\n",
    "                #Note.write(f'para1:,{para1}\\npara2:{para2}\\npara3:{para3}\\npara4:{para4}\\nct:{ct}')\n",
    "            sequence_outputs.append(ht)\n",
    "        \n",
    "        #Note.write(str(Para))\n",
    "        #Note.close()\n",
    "        sequence_outputs = tf.stack(sequence_outputs)\n",
    "        sequence_outputs = tf.transpose(sequence_outputs,(1, 0, 2))\n",
    "        if self.return_sequences:\n",
    "            return sequence_outputs\n",
    "        return sequence_outputs[:, -1 ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputdata KerasTensor(type_spec=TensorSpec(shape=(None, 1, 28), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Model: \"MyModelMLP\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 28)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1, 128)       3712        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 1, 128)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               multiple             0           max_pooling1d[0][0]              \n",
      "                                                                 custom_lstm_1[0][0]              \n",
      "                                                                 custom_lstm_1[1][0]              \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "custom_lstm_1 (CustomLSTM)      (None, 1, 128)       49536       dropout[0][0]                    \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1, 128)       512         dropout[1][0]                    \n",
      "                                                                 dropout[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 8)         1032        batch_normalization[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8)            0           dropout[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            18          flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 54,810\n",
      "Trainable params: 54,554\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class my_model(Model):\n",
    "    def __init__(self, input_shape, **kwargs):\n",
    "        super().__init__(**kwargs) \n",
    "        \n",
    "        the_units = 128\n",
    "        self.CNN   = Conv1D(the_units,1,padding=\"valid\",activation=\"relu\")\n",
    "        self.POLL  = MaxPool1D(1)\n",
    "        self.FLATT = Flatten()\n",
    "        self.LSTM0 = CustomLSTM(output_size=the_units,return_sequences=True)\n",
    "                        #kernel_initializer=tf.keras.initializers.glorot_normal(seed=2),bias_initializer=tf.keras.initializers.Zeros())\n",
    "        self.LSTM1 = CustomLSTM(output_size=the_units,return_sequences=True)\n",
    "        self.LSTM2 = CustomLSTM(output_size=the_units)\n",
    "        self.BAT   = BatchNormalization()\n",
    "        self.DROP  = Dropout(rate=0.2)\n",
    "        self.DENS  = Dense(8, activation='relu')\n",
    "        self.OUT   = Dense(2, activation='softmax')\n",
    "        self.resha = Reshape((1, 28))\n",
    "        \n",
    "        # 模型的参数\n",
    "        self.input_layer = tf.keras.layers.Input(input_shape)\n",
    "        self.out = self.call(self.input_layer)\n",
    "        \n",
    "        super().__init__( inputs=self.input_layer,outputs=self.out, **kwargs)\n",
    "    \n",
    "    # 初始化模型的参数\n",
    "    def build(self):\n",
    "        self._is_graph_network = True\n",
    "        self._init_graph_network(inputs=self.input_layer,outputs=self.out)\n",
    "    \n",
    "    def call(self, inputdata, **kwargs):\n",
    "                \n",
    "        #x1 = self.LSTM0(inputdata)\n",
    "        print('inputdata',inputdata)\n",
    "        x1 = self.CNN(inputdata)\n",
    "        #x1 = self.LSTM0(inputdata)\n",
    "        x1 = self.POLL(x1)\n",
    "        c = self.DROP(x1)\n",
    "        #c = self.BAT(x1)\n",
    "\n",
    "        c = self.LSTM1(c)\n",
    "        c = self.DROP(c)\n",
    "        c = self.BAT(c)\n",
    "        \n",
    "        c = self.LSTM1(c)\n",
    "        c = self.DROP(c)\n",
    "        c = self.BAT(c)\n",
    "        \n",
    "        # # d = self.LSTM2(c)\n",
    "        # # d = self.BAT(d)\n",
    "        # c = self.LSTM1(c)\n",
    "        # c = self.DROP(c)\n",
    "        # c = self.BAT(c)\n",
    "                        \n",
    "        d = self.DENS(c)\n",
    "        d = self.DROP(d)\n",
    "        \n",
    "        d = self.FLATT(d)\n",
    "        out = self.OUT(d)\n",
    "        return out\n",
    "    # AFAIK: The most convenient method to print model.summary() \n",
    "    # similar to the sequential or functional API like.\n",
    "    def build_graph(self):\n",
    "        #x = Input(shape=(dim))\n",
    "        x = Input()\n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "mymodel2 = my_model((1,28), name='MyModelMLP')\n",
    "# mymodel2(X_train)\n",
    "mymodel2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = 100  # 模型迭代的次数\n",
    "Batch_Size = 64  # 批量训练的样本的个数\n",
    "Out_Class = 2  # 输出的类别的个数,0-9共10类\n",
    "# 模型编译\n",
    "#mYMODEL = my_model((1,28),name=\"mYMODEL\")\n",
    "#mYMODEL(X_train)\n",
    "mymodel2.compile(loss='binary_crossentropy',#categorical_crossentropy', binary_crossentropy\n",
    "                optimizer='adam', metrics=['categorical_accuracy'])  \n",
    "\n",
    "# train_label_cate = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "# testlabels = tf.keras.utils.to_categorical(test_labels, 10)\n",
    "checkpoint_path = \"./models/cp-{categorical_accuracy:.5f}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 创建一个回调，保证验证数据集准确率最大\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='categorical_accuracy',\n",
    "                                                mode='max',\n",
    "                                                verbose=2,\n",
    "                                                save_best_only=True)\n",
    "#                                              filepath=filepath,\n",
    "#                                             save_weights_only=False,\n",
    "#                                             monitor='categorical_accuracy',\n",
    "#                                             mode='max',\n",
    "#                                             save_best_only=True)\n",
    "\n",
    "# 动态更改学习率：在模型的回调中使用\n",
    "def scheduler(epoch):  # 根据epoch动态更改学习率的参数\n",
    "    if epoch < 10:\n",
    "        return 0.13\n",
    "    else:\n",
    "        return 0.13 * tf.math.exp(0.1 * (10 - epoch))\n",
    "    \n",
    "lr_back = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "inputdata Tensor(\"IteratorGetNext:0\", shape=(None, 1, 28), dtype=float32)\n",
      "inputdata Tensor(\"IteratorGetNext:0\", shape=(None, 1, 28), dtype=float32)\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node MyModelMLP/conv1d/conv1d (defined at C:\\Users\\20987\\AppData\\Local\\Temp\\ipykernel_14988\\3388358910.py:34) ]] [Op:__inference_train_function_2097]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\20987\\Desktop\\Pistachio_DeepLearning\\diyLSTM.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/diyLSTM.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Note = open('LSTM-para.txt',mode='w')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/diyLSTM.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Note.close()\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/diyLSTM.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mymodel2\u001b[39m.\u001b[39;49mfit(X_train,Y_train, batch_size\u001b[39m=\u001b[39;49mBatch_Size, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/diyLSTM.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49mEpoch, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/Pistachio_DeepLearning/diyLSTM.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcp_callback)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    885\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 888\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    889\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    891\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    892\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node MyModelMLP/conv1d/conv1d (defined at C:\\Users\\20987\\AppData\\Local\\Temp\\ipykernel_14988\\3388358910.py:34) ]] [Op:__inference_train_function_2097]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Note = open('LSTM-para.txt',mode='w')\n",
    "# Note.close()\n",
    "mymodel2.fit(X_train,Y_train, batch_size=Batch_Size, \n",
    "            epochs=Epoch, verbose=2, validation_split=0.1, \n",
    "            callbacks=cp_callback)\n",
    "            #callbacks=[cp_callback, lr_back])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型,按照模型最后的参数计算\n",
    "test_loss, test_acc = mymodel2.evaluate(X_test, Y_test)\n",
    "\n",
    "print('测试数据集成本：{:.8f},准确率{:.8f}%%'. format(test_loss, 100*test_acc))\n",
    "\n",
    "\n",
    "best_para = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print('最优的参数文件：', best_para)\n",
    "#best_para = './models\\cp-0.92987.ckpt'\n",
    "mymodel2.load_weights(best_para)\n",
    "\n",
    "predict_loss, predict_acc = mymodel2.evaluate(X_test, Y_test)\n",
    "print('使用训练后的参数','成本:', predict_loss, '准确率', predict_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用其他数据集去做验证\n",
    "可行性分析，会拿几种进行对比\n",
    "数据分析与处理\n",
    "在输入到模型之前，有一个优化器，该优化器是对指标进行排序的，是一个固定的模式\n",
    "顺序优化的优化器。基于优化器，针对大数据，使用LSTM对所有指标进行分类（重要性分类），对几类的数据做相应优化，\n",
    "越不重要越先输入还是越重要越先输入。重要性体现在什么地方。\n",
    "\n",
    "优化器-> LSTM（对内部超参数进行优化）\n",
    "找到其他LSTM的改进，进行实验。最近三年来新的LSTM改进。\n",
    "\n",
    "改进——>.0本身的改进\n",
    "    -->基本原理的改进，逻辑门的改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pickletools import optimize\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     CustomLSTM(output_size=128),\n",
    "#     tf.keras.layers.Dense(2, activation='softmax')\n",
    "# ])\n",
    "# model.compile(loss='binary_crossentropy',#categorical_crossentropy', binary_crossentropy\n",
    "#                 optimizer='adam', metrics=['categorical_accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train,Y_train,batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33d73dfb9d58d1e4c0ed15f266f7c1fd1b5e79268076ebae9c660cb33abbd60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
