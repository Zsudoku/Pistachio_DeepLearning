{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import minmax_scale \n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.layers import DenseFeatures,Dense,Dropout,Conv1D,MaxPooling1D,Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import h5py\n",
    "print(tf.__version__)   # 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13611, 17)\n",
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0  28395    610.291       208.178117       173.888747      1.197191   \n",
      "1  28734    638.018       200.524796       182.734419      1.097356   \n",
      "2  29380    624.110       212.826130       175.931143      1.209713   \n",
      "3  30008    645.884       210.557999       182.516516      1.153638   \n",
      "4  30140    620.134       201.847882       190.279279      1.060798   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "1      0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
      "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
      "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
      "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
      "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
      "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
      "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
      "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('gandou.csv')\n",
    "df=df.copy()\n",
    "print(df.shape)  # (250, 20)\n",
    "print(df.head(5))\n",
    "# dataframe =shuffle(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3546\n",
       "6    2636\n",
       "5    2027\n",
       "4    1928\n",
       "2    1630\n",
       "0    1322\n",
       "1     522\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df['Class'])\n",
    "features = df.drop('Class', axis=1)\n",
    "# features = (features - features.min()) / (features.max() - features.min())\n",
    "features = (features - features.mean()) / features.std()\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=features[:,:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_num=[16,32,64,128,256]\n",
    "k_num=[x for x in range(3, 6)]\n",
    "m_num=[2,4,6]\n",
    "dout_num=[0.3,0.5,0.7]\n",
    "dese_num=[16,32,64,128]\n",
    "list_loss=[]\n",
    "list_acc=[]\n",
    "list_v_loss=[]\n",
    "list_v_acc=[]\n",
    "value_num=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16, 16)            64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 2,247\n",
      "Trainable params: 2,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "341/341 [==============================] - 1s 2ms/step - loss: 0.8513 - accuracy: 0.7165 - val_loss: 0.3335 - val_accuracy: 0.8909\n",
      "Epoch 2/50\n",
      "341/341 [==============================] - 1s 1ms/step - loss: 0.3394 - accuracy: 0.8815 - val_loss: 0.2620 - val_accuracy: 0.9030\n",
      "Epoch 3/50\n",
      "168/341 [=============>................] - ETA: 0s - loss: 0.3116 - accuracy: 0.8934"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\20987\\Desktop\\dataset\\开心果数据集\\Pistachio_DeepLearning\\pre_1d.ipynb Cell 8\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m#想0,1,2,3这种就带sparse，像[0,0,1]张量分类就不带sparse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(features, labels, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m list_loss\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20987/Desktop/dataset/%E5%BC%80%E5%BF%83%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86/Pistachio_DeepLearning/pre_1d.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m list_acc\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\20987\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "progress_num=0\n",
    "for i in range(len(f_num)):\n",
    "    for j in range(len(k_num)):\n",
    "        for k in range(len(m_num)):\n",
    "            for p in range(len(dout_num)):\n",
    "                for q in range(len(dese_num)):\n",
    "                    model = Sequential([\n",
    "                        Conv1D(f_num[i],k_num[j],padding='same',activation='relu',input_shape=(16,1)),#这里一定要有input_shape,16和特征数相对应\n",
    "                        MaxPooling1D(m_num[k]),\n",
    "                        Dropout(dout_num[p]),\n",
    "                        Flatten(),\n",
    "                        Dense(dese_num[q], activation='relu'),\n",
    "                        Dense(7, activation='softmax')\n",
    "            ])\n",
    "                    print(model.summary())\n",
    "                    model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',#想0,1,2,3这种就带sparse，像[0,0,1]张量分类就不带sparse\n",
    "                        metrics=['accuracy'])\n",
    "                    \n",
    "                    history=model.fit(features, labels, validation_split=0.2, epochs=50, batch_size=32, shuffle=True)\n",
    "                    list_loss.append(max(history.history['loss']))\n",
    "                    list_acc.append(max(history.history['accuracy']))\n",
    "                    list_v_loss.append(max(history.history['val_loss']))\n",
    "                    list_v_acc.append(max(history.history['val_accuracy']))\n",
    "                    ap_value=[]\n",
    "                    ap_value=[i,j,k,p,q]\n",
    "                    value_num.append(ap_value)\n",
    "                    progress_num+=1\n",
    "                    if progress_num%100==0:\n",
    "                        print(progress_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(max(list_v_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_acc)):\n",
    "    with open('./rulest/3.txt', 'a+') as f:\n",
    "        print('acc:'+str(list_acc[i])+',v_acc:'+str(list_v_acc[i])+',num:'+str(value_num[i]),file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16,257):\n",
    "    for j in range(3,17):\n",
    "        with open('./rulest/2.txt', 'a+') as f:\n",
    "            # print('Hello World!', file=f)\n",
    "            print('f_num:'+str(i)+',k_num:'+str(j)+', acc'+str(list_acc[i+j-19]),file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33d73dfb9d58d1e4c0ed15f266f7c1fd1b5e79268076ebae9c660cb33abbd60e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
